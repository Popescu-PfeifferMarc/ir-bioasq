{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from dask import dataframe as dd\n",
    "import numpy as np\n",
    "import gensim\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import TfidfModel\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.similarities import SparseMatrixSimilarity\n",
    "from rank_bm25 import BM25Okapi  # BM25 library\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import faiss  # For approximate nearest neighbor search\n",
    "import torch\n",
    "from bm25s import tokenize, BM25\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data and query documents -- Run the 2 cells below for having a global dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Use regular expressions to split text into words\n",
    "    words = simple_preprocess(text)\n",
    "    # Remove stopwords and lemmatize\n",
    "    return [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
    "\n",
    "\n",
    "def load_and_preprocess_documents(file_path):\n",
    "    print(f\"Loading documents from {file_path}\")\n",
    "    ddf = dd.read_csv(file_path)\n",
    "    print(\"Dropping missing rows...\")\n",
    "    # Drop rows with missing values in specified columns\n",
    "    ddf = ddf.dropna(subset=[\"pmid\", \"title\", \"abstract\"])\n",
    "    print(\"Preprocessing text...\")\n",
    "    ddf[\"processed_text\"] = ddf[\"abstract\"].apply(preprocess_text, meta=(\"x\", \"object\"))\n",
    "    df = ddf.compute()\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_golden_data(golden_file_path):\n",
    "    print(f\"Loading golden data from {golden_file_path}\")\n",
    "    with open(golden_file_path, \"r\") as f:\n",
    "        golden_data = json.load(f)\n",
    "\n",
    "    # Initialize lists to store the extracted data\n",
    "    queries = []\n",
    "    golden_docs = []\n",
    "    golden_snippets = []\n",
    "\n",
    "    # Iterate through each question in the JSON data\n",
    "    for question in golden_data.get(\"questions\", []):\n",
    "        queries.append(question.get(\"body\", \"\"))\n",
    "        golden_docs.append(question.get(\"documents\", []))\n",
    "        golden_snippets.append(\n",
    "            [snippet.get(\"text\", \"\") for snippet in question.get(\"snippets\", [])]\n",
    "        )\n",
    "\n",
    "    # Create a DataFrame from the extracted data\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"query\": queries,\n",
    "            \"golden_docs\": golden_docs,\n",
    "            \"golden_snippets\": golden_snippets,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading documents from /Users/onurcanmemis/Desktop/Lectures/Information_Retrieval/Project/ir-bioasq/main_articles_head_1m.csv\n",
      "Dropping missing rows...\n",
      "Preprocessing text...\n",
      "Loading golden data from /Users/onurcanmemis/Desktop/Lectures/Information_Retrieval/Project/ir-bioasq/dataset/12B4_golden.json\n"
     ]
    }
   ],
   "source": [
    "golden_file_path = \"/Users/onurcanmemis/Desktop/Lectures/Information_Retrieval/Project/ir-bioasq/dataset/12B4_golden.json\"\n",
    "dataset_path = \"/Users/onurcanmemis/Desktop/Lectures/Information_Retrieval/Project/ir-bioasq/main_articles_head_1m.csv\"\n",
    "df = load_and_preprocess_documents(dataset_path)\n",
    "# For query lists of 1 query we should modify the class\n",
    "query_df = load_golden_data(golden_file_path)\n",
    "query_documents = query_df[\"query\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trial Board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure stopwords are loaded\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Use regular expressions to split text into words\n",
    "    words = simple_preprocess(text)\n",
    "    # Remove stopwords and lemmatize\n",
    "    return [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
    "\n",
    "\n",
    "def load_and_preprocess_documents(file_path):\n",
    "    ddf = dd.read_csv(file_path)\n",
    "    # Drop rows with missing values in specified columns\n",
    "    ddf = ddf.dropna(subset=[\"pmid\", \"title\", \"abstract\"])\n",
    "    ddf[\"processed_text\"] = ddf[\"abstract\"].apply(preprocess_text, meta=(\"x\", \"object\"))\n",
    "    df = ddf.compute()\n",
    "    return df\n",
    "\n",
    "\n",
    "dictionary = Dictionary()\n",
    "BoW_corpus = [\n",
    "    dictionary.doc2bow(doc, allow_update=True) for doc in df[\"processed_text\"]\n",
    "]\n",
    "tfidf = TfidfModel(BoW_corpus, smartirs=\"nfc\")\n",
    "tfidf_corpus = tfidf[BoW_corpus]\n",
    "index = SparseMatrixSimilarity(tfidf_corpus, num_features=len(dictionary))\n",
    "\n",
    "most_relevant_documents = []\n",
    "for query in query_documents:\n",
    "    relevant_documents = []\n",
    "    query_doc = preprocess_text(query)\n",
    "    # Convert the query to BoW format\n",
    "    query_bow = dictionary.doc2bow(query_doc)\n",
    "    # Transform the query to TF-IDF representation\n",
    "    query_tfidf = tfidf[query_bow]\n",
    "    # Compute similarities\n",
    "    similarities = index[query_tfidf]\n",
    "    sorted_docs = sorted(enumerate(similarities), key=lambda x: x[1], reverse=True)\n",
    "    for doc_id, score in sorted_docs[:10]:\n",
    "        relevant_documents.append(\n",
    "            f\"http://www.ncbi.nlm.nih.gov/pubmed/{df.iloc[doc_id]['pmid']}\"\n",
    "        )\n",
    "    most_relevant_documents.append(relevant_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VSM Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Logarithmic\n",
    "> lfu\n",
    "* logarithmic frequency (l)\n",
    "* idf (f)\n",
    "* Pivoted unique normalization (u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TF_IDF_Gensim_Log:\n",
    "    def __init__(self, method=\"lfu\"):\n",
    "        self.method = method\n",
    "        self.dictionary = None\n",
    "        self.tfidf = None\n",
    "        self.index = None\n",
    "\n",
    "    def preprocess_text(self, text):\n",
    "        # Use regular expressions to split text into words\n",
    "        words = simple_preprocess(text)\n",
    "        # Remove stopwords and lemmatize\n",
    "        return [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
    "\n",
    "    def create_tfidf_model(self, processed_texts):\n",
    "        \"\"\"\n",
    "        Create a TF-IDF model and similarity index from preprocessed texts.\n",
    "\n",
    "        Parameters:\n",
    "        processed_texts (list of list of str): Preprocessed documents, where each document is a list of tokens.\n",
    "        \"\"\"\n",
    "        self.dictionary = Dictionary(processed_texts)\n",
    "        bow_corpus = [self.dictionary.doc2bow(doc) for doc in processed_texts]\n",
    "        self.tfidf = TfidfModel(bow_corpus, smartirs=self.method)\n",
    "        tfidf_corpus = self.tfidf[bow_corpus]\n",
    "        self.index = SparseMatrixSimilarity(\n",
    "            tfidf_corpus, num_features=len(self.dictionary)\n",
    "        )\n",
    "\n",
    "    def get_most_relevant_documents(self, queries: List[List[str]], top_n=10):\n",
    "        \"\"\"\n",
    "        Retrieve the most relevant documents for each query.\n",
    "\n",
    "        Parameters:\n",
    "        queries (list of list of str): List of queries, where each query is a list of preprocessed tokens.\n",
    "        top_n (int): Number of top relevant documents to retrieve for each query.\n",
    "\n",
    "        Returns:\n",
    "        list of list of tuple: Each inner list contains tuples of (document_id, similarity_score) for the top_n documents.\n",
    "        \"\"\"\n",
    "        most_relevant_documents = []\n",
    "        most_relevant_snippets = []\n",
    "        for query in queries:\n",
    "            relevant_documents = []\n",
    "            snippets = []\n",
    "            query = self.preprocess_text(query)\n",
    "            query_bow = self.dictionary.doc2bow(query)\n",
    "            query_tfidf = self.tfidf[query_bow]\n",
    "            similarities = self.index[query_tfidf]\n",
    "            sorted_docs = sorted(\n",
    "                enumerate(similarities), key=lambda x: x[1], reverse=True\n",
    "            )\n",
    "            for doc_id, score in sorted_docs[:top_n]:\n",
    "                relevant_documents.append(\n",
    "                    f\"http://www.ncbi.nlm.nih.gov/pubmed/{df.iloc[doc_id]['pmid']}\"\n",
    "                )\n",
    "                # Score can be added later!\n",
    "            most_relevant_documents.append(relevant_documents)\n",
    "            for documents in relevant_documents:\n",
    "                pmid = int(documents.rsplit(\"/\", 1)[-1])\n",
    "                sentences = sent_tokenize(df[df.pmid == pmid].abstract.values[0])\n",
    "                for sentence in sentences:\n",
    "                    sentence_tokens = self.preprocess_text(sentence)\n",
    "                    sentence_bow = self.dictionary.doc2bow(sentence_tokens)\n",
    "                    sentence_tfidf = self.tfidf[sentence_bow]\n",
    "                    snippet_score = sum(\n",
    "                        score\n",
    "                        for term_id, score in sentence_tfidf\n",
    "                        if term_id\n",
    "                        in [self.dictionary.token2id.get(token) for token in query]\n",
    "                    )\n",
    "                    snippets.append(\n",
    "                        {\n",
    "                            \"text\": sentence,\n",
    "                            \"source\": pmid,\n",
    "                            \"score\": snippet_score,\n",
    "                        }\n",
    "                    )\n",
    "            top_snippets = sorted(snippets, key=lambda x: x[\"score\"], reverse=True)[\n",
    "                :top_n\n",
    "            ]\n",
    "            most_relevant_snippets.append(top_snippets)\n",
    "\n",
    "        return most_relevant_documents, most_relevant_snippets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Raw\n",
    "> nfc\n",
    "* raw term frequency (n)\n",
    "* idf (f)\n",
    "* cosine normalization (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TF_IDF_Gensim_Raw:\n",
    "    def __init__(self, method=\"nfc\"):\n",
    "        self.method = method\n",
    "        self.dictionary = None\n",
    "        self.tfidf = None\n",
    "        self.index = None\n",
    "\n",
    "    def preprocess_text(self, text):\n",
    "        # Use regular expressions to split text into words\n",
    "        words = simple_preprocess(text)\n",
    "        # Remove stopwords and lemmatize\n",
    "        return [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
    "\n",
    "    def create_tfidf_model(self, processed_texts):\n",
    "        \"\"\"\n",
    "        Create a TF-IDF model and similarity index from preprocessed texts.\n",
    "\n",
    "        Parameters:\n",
    "        processed_texts (list of list of str): Preprocessed documents, where each document is a list of tokens.\n",
    "        \"\"\"\n",
    "        self.dictionary = Dictionary(processed_texts)\n",
    "        bow_corpus = [self.dictionary.doc2bow(doc) for doc in processed_texts]\n",
    "        self.tfidf = TfidfModel(bow_corpus, smartirs=self.method)\n",
    "        tfidf_corpus = self.tfidf[bow_corpus]\n",
    "        self.index = SparseMatrixSimilarity(\n",
    "            tfidf_corpus, num_features=len(self.dictionary)\n",
    "        )\n",
    "\n",
    "    def get_most_relevant_documents(self, queries: List[List[str]], top_n=10):\n",
    "        \"\"\"\n",
    "        Retrieve the most relevant documents for each query.\n",
    "\n",
    "        Parameters:\n",
    "        queries (list of list of str): List of queries, where each query is a list of preprocessed tokens.\n",
    "        top_n (int): Number of top relevant documents to retrieve for each query.\n",
    "\n",
    "        Returns:\n",
    "        list of list of tuple: Each inner list contains tuples of (document_id, similarity_score) for the top_n documents.\n",
    "        \"\"\"\n",
    "        most_relevant_documents = []\n",
    "        most_relevant_snippets = []\n",
    "        for query in queries:\n",
    "            relevant_documents = []\n",
    "            snippets = []\n",
    "            query = self.preprocess_text(query)\n",
    "            query_bow = self.dictionary.doc2bow(query)\n",
    "            query_tfidf = self.tfidf[query_bow]\n",
    "            similarities = self.index[query_tfidf]\n",
    "            sorted_docs = sorted(\n",
    "                enumerate(similarities), key=lambda x: x[1], reverse=True\n",
    "            )\n",
    "            for doc_id, score in sorted_docs[:top_n]:\n",
    "                relevant_documents.append(\n",
    "                    f\"http://www.ncbi.nlm.nih.gov/pubmed/{df.iloc[doc_id]['pmid']}\"\n",
    "                )\n",
    "                # Score can be added later!\n",
    "            most_relevant_documents.append(relevant_documents)\n",
    "            for documents in relevant_documents:\n",
    "                pmid = int(documents.rsplit(\"/\", 1)[-1])\n",
    "                sentences = sent_tokenize(df[df.pmid == pmid].abstract.values[0])\n",
    "                for sentence in sentences:\n",
    "                    sentence_tokens = self.preprocess_text(sentence)\n",
    "                    sentence_bow = self.dictionary.doc2bow(sentence_tokens)\n",
    "                    sentence_tfidf = self.tfidf[sentence_bow]\n",
    "                    snippet_score = sum(\n",
    "                        score\n",
    "                        for term_id, score in sentence_tfidf\n",
    "                        if term_id\n",
    "                        in [self.dictionary.token2id.get(token) for token in query]\n",
    "                    )\n",
    "                    snippets.append(\n",
    "                        {\n",
    "                            \"text\": sentence,\n",
    "                            \"source\": pmid,\n",
    "                            \"score\": snippet_score,\n",
    "                        }\n",
    "                    )\n",
    "            top_snippets = sorted(snippets, key=lambda x: x[\"score\"], reverse=True)[\n",
    "                :top_n\n",
    "            ]\n",
    "            most_relevant_snippets.append(top_snippets)\n",
    "\n",
    "        return most_relevant_documents, most_relevant_snippets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Augmented\n",
    "> afc\n",
    "* augmented (a)\n",
    "* idf (f)\n",
    "* cosine normalization (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TF_IDF_Gensim_Augmented:\n",
    "    def __init__(self, method=\"afc\"):\n",
    "        self.method = method\n",
    "        self.dictionary = None\n",
    "        self.tfidf = None\n",
    "        self.index = None\n",
    "\n",
    "    def preprocess_text(self, text):\n",
    "        # Use regular expressions to split text into words\n",
    "        words = simple_preprocess(text)\n",
    "        # Remove stopwords and lemmatize\n",
    "        return [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
    "\n",
    "    def create_tfidf_model(self, processed_texts):\n",
    "        \"\"\"\n",
    "        Create a TF-IDF model and similarity index from preprocessed texts.\n",
    "\n",
    "        Parameters:\n",
    "        processed_texts (list of list of str): Preprocessed documents, where each document is a list of tokens.\n",
    "        \"\"\"\n",
    "        self.dictionary = Dictionary(processed_texts)\n",
    "        bow_corpus = [self.dictionary.doc2bow(doc) for doc in processed_texts]\n",
    "        self.tfidf = TfidfModel(bow_corpus, smartirs=self.method)\n",
    "        tfidf_corpus = self.tfidf[bow_corpus]\n",
    "        self.index = SparseMatrixSimilarity(\n",
    "            tfidf_corpus, num_features=len(self.dictionary)\n",
    "        )\n",
    "\n",
    "    def get_most_relevant_documents(self, queries: List[List[str]], top_n=10):\n",
    "        \"\"\"\n",
    "        Retrieve the most relevant documents for each query.\n",
    "\n",
    "        Parameters:\n",
    "        queries (list of list of str): List of queries, where each query is a list of preprocessed tokens.\n",
    "        top_n (int): Number of top relevant documents to retrieve for each query.\n",
    "\n",
    "        Returns:\n",
    "        list of list of tuple: Each inner list contains tuples of (document_id, similarity_score) for the top_n documents.\n",
    "        \"\"\"\n",
    "        most_relevant_documents = []\n",
    "        most_relevant_snippets = []\n",
    "        for query in queries:\n",
    "            relevant_documents = []\n",
    "            snippets = []\n",
    "            query = self.preprocess_text(query)\n",
    "            query_bow = self.dictionary.doc2bow(query)\n",
    "            query_tfidf = self.tfidf[query_bow]\n",
    "            similarities = self.index[query_tfidf]\n",
    "            sorted_docs = sorted(\n",
    "                enumerate(similarities), key=lambda x: x[1], reverse=True\n",
    "            )\n",
    "            for doc_id, score in sorted_docs[:top_n]:\n",
    "                relevant_documents.append(\n",
    "                    f\"http://www.ncbi.nlm.nih.gov/pubmed/{df.iloc[doc_id]['pmid']}\"\n",
    "                )\n",
    "                # Score can be added later!\n",
    "            most_relevant_documents.append(relevant_documents)\n",
    "            for documents in relevant_documents:\n",
    "                pmid = int(documents.rsplit(\"/\", 1)[-1])\n",
    "                sentences = sent_tokenize(df[df.pmid == pmid].abstract.values[0])\n",
    "                for sentence in sentences:\n",
    "                    sentence_tokens = self.preprocess_text(sentence)\n",
    "                    sentence_bow = self.dictionary.doc2bow(sentence_tokens)\n",
    "                    sentence_tfidf = self.tfidf[sentence_bow]\n",
    "                    snippet_score = sum(\n",
    "                        score\n",
    "                        for term_id, score in sentence_tfidf\n",
    "                        if term_id\n",
    "                        in [self.dictionary.token2id.get(token) for token in query]\n",
    "                    )\n",
    "                    snippets.append(\n",
    "                        {\n",
    "                            \"text\": sentence,\n",
    "                            \"source\": pmid,\n",
    "                            \"score\": snippet_score,\n",
    "                        }\n",
    "                    )\n",
    "            top_snippets = sorted(snippets, key=lambda x: x[\"score\"], reverse=True)[\n",
    "                :top_n\n",
    "            ]\n",
    "            most_relevant_snippets.append(top_snippets)\n",
    "\n",
    "        return most_relevant_documents, most_relevant_snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the DocumentSimilarity object\n",
    "doc_sim = TF_IDF_Gensim_Log(method=\"lfu\")\n",
    "# Create the TF-IDF model and similarity index\n",
    "doc_sim.create_tfidf_model(df[\"processed_text\"])\n",
    "# Retrieve the most relevant documents for each query\n",
    "doc, snippets = doc_sim.get_most_relevant_documents(query_documents, top_n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilistic Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BM25ModelWithPandas:\n",
    "    def __init__(self):\n",
    "        # Initialize stop words and lemmatizer\n",
    "        self.stop_words = set(stopwords.words(\"english\"))\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"\n",
    "        Preprocesses text by removing stopwords, applying lowercase, and lemmatization.\n",
    "        If for_bm25 is True, returns a list of tokens for BM25. Otherwise, returns a single string.\n",
    "        \"\"\"\n",
    "        tokens = text.lower().split()  # Tokenize and convert to lowercase\n",
    "        tokens = [\n",
    "            word for word in tokens if word.isalnum() and word not in self.stop_words\n",
    "        ]  # Remove stop words and punctuation\n",
    "        tokens = [\n",
    "            self.lemmatizer.lemmatize(word) for word in tokens\n",
    "        ]  # Apply lemmatization only\n",
    "        return tokens\n",
    "\n",
    "    def load_documents(self, file_path):\n",
    "        \"\"\"\n",
    "        Loads CSV data using Pandas and preprocesses the `title` and `abstract` fields.\n",
    "        Assumes the file has columns `pmid`, `title`, and `abstract`.\n",
    "        \"\"\"\n",
    "        print(f\"Loading documents from {file_path}\")\n",
    "        df = pd.read_csv(file_path)\n",
    "        df = df.dropna(\n",
    "            subset=[\"pmid\", \"title\", \"abstract\"]\n",
    "        )  # Drop rows with missing values\n",
    "\n",
    "        # Combine title and abstract, and preprocess\n",
    "        df[\"raw_text\"] = df[\"title\"] + \" \" + df[\"abstract\"]\n",
    "        df[\"preprocessed_text\"] = df[\"raw_text\"].apply(self.preprocess_text)\n",
    "\n",
    "        return df\n",
    "\n",
    "    def calculate_bm25_scores(self, query_tokens, documents):\n",
    "        \"\"\"\n",
    "        Uses BM25 to calculate relevance scores between the query and all documents.\n",
    "        \"\"\"\n",
    "        bm25 = BM25Okapi(list(documents[\"preprocessed_text\"]))\n",
    "        relevance_scores = bm25.get_scores(query_tokens)\n",
    "        return relevance_scores\n",
    "\n",
    "    def get_top_snippets(self, query_tokens, top_documents, top_n=10):\n",
    "        \"\"\"\n",
    "        Extracts and ranks snippets globally from the top documents using BM25.\n",
    "        \"\"\"\n",
    "        snippets = []\n",
    "\n",
    "        for _, doc in top_documents.iterrows():\n",
    "            pmid, abstract = doc[\"pmid\"], doc[\"raw_text\"]\n",
    "            sentences = sent_tokenize(abstract)  # Split the abstract into sentences\n",
    "\n",
    "            for sentence in sentences:\n",
    "                preprocessed_sentence = self.preprocess_text(sentence)\n",
    "                snippets.append(\n",
    "                    {\"text\": sentence, \"tokens\": preprocessed_sentence, \"source\": pmid}\n",
    "                )\n",
    "\n",
    "        # Combine all snippets into a single list for BM25\n",
    "        snippet_texts = [snippet[\"tokens\"] for snippet in snippets]\n",
    "        bm25 = BM25Okapi(snippet_texts)\n",
    "        snippet_scores = bm25.get_scores(query_tokens)\n",
    "\n",
    "        # Add scores to snippets and sort them globally\n",
    "        for i, snippet in enumerate(snippets):\n",
    "            snippet[\"score\"] = snippet_scores[i]\n",
    "\n",
    "        top_snippets = sorted(snippets, key=lambda x: x[\"score\"], reverse=True)[:top_n]\n",
    "        return top_snippets\n",
    "\n",
    "    def get_relevant_documents_and_snippets(\n",
    "        self, query, file_path, top_n_docs=10, top_n_snippets=10\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Retrieves top N most relevant documents and globally ranks snippets from them.\n",
    "        \"\"\"\n",
    "        # Load documents\n",
    "        documents = self.load_documents(file_path)\n",
    "\n",
    "        if len(documents) == 0:\n",
    "            print(\"No valid documents found.\")\n",
    "            return [], []\n",
    "\n",
    "        # Preprocess the query\n",
    "        query_tokens = self.preprocess_text(query)\n",
    "\n",
    "        # Calculate BM25 relevance scores\n",
    "        relevance_scores = self.calculate_bm25_scores(query_tokens, documents)\n",
    "        documents[\"score\"] = relevance_scores\n",
    "\n",
    "        # Get top N documents\n",
    "        top_documents = documents.nlargest(top_n_docs, \"score\")\n",
    "\n",
    "        # Rank snippets globally from top documents\n",
    "        top_snippets = self.get_top_snippets(\n",
    "            query_tokens, top_documents, top_n_snippets\n",
    "        )\n",
    "\n",
    "        # Return both top documents and snippets\n",
    "        return top_documents, top_snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading documents from /Users/onurcanmemis/Desktop/Lectures/Information_Retrieval/Project/ir-bioasq/main_articles_head1000.csv\n",
      "\n",
      "Top Documents:\n",
      "PMC ID: 2143, Score: 13.0717\n",
      "PMC ID: 1126, Score: 9.4150\n",
      "PMC ID: 2142, Score: 8.3898\n",
      "PMC ID: 1990, Score: 6.2001\n",
      "PMC ID: 938, Score: 6.1988\n",
      "PMC ID: 884, Score: 5.9103\n",
      "PMC ID: 1468, Score: 5.7332\n",
      "PMC ID: 1628, Score: 5.7323\n",
      "PMC ID: 1792, Score: 5.7181\n",
      "PMC ID: 1629, Score: 5.5253\n",
      "\n",
      "Top Snippets:\n",
      "Source: 2143\n",
      "Snippet: Rapid cooling and sudden freezing decreased the residual activities of interferons at pH 2 and 9 more than \"normal\" cooling, an effect not observed at pH 7.\n",
      "Score: 4.3776\n",
      "\n",
      "Source: 1792\n",
      "Snippet: Effect of environmental pH on adenovirus-associated virus.\n",
      "Score: 4.1220\n",
      "\n",
      "Source: 2143\n",
      "Snippet: The stabilizing effect of pH during heating on interferon in solution was greatest at low pH, such that pH 2 greater than pH 5 greater than pH 7 greater than or equal to pH 9; freeze-dried preparations of interferon were also more heat-stable at acid pH than at neutral pH.\n",
      "Score: 3.9315\n",
      "\n",
      "Source: 884\n",
      "Snippet: Comparative study of virological infections in asthmatic and nonasthmatic children.\n",
      "Score: 3.2311\n",
      "\n",
      "Source: 1792\n",
      "Snippet: Under the acid conditions studied, the adenovirus helper and cell activities were only slightly suppressed, with the greatest effect due to aggregation of the virus particles.\n",
      "Score: 2.6973\n",
      "\n",
      "Source: 2143\n",
      "Snippet: It is postulated that the physicochemical alterations in the aqueous environment significantly affecting the stability of interferon operate by producing changes in the size and/or conformation of interferon molecules.\n",
      "Score: 2.6757\n",
      "\n",
      "Source: 2143\n",
      "Snippet: Interferon heated to 80degree C could not be reactivated at 40degree C or 55degree C. Interferon of higher apparent molecular weight was more heat-stable than that with lower apparent molecular weight.\n",
      "Score: 2.5460\n",
      "\n",
      "Source: 2143\n",
      "Snippet: The rate of cooling of heated interferon significantly influenced its residual activity.\n",
      "Score: 2.4958\n",
      "\n",
      "Source: 1468\n",
      "Snippet: The mixtures of viral fragments exhibited an increased deacetylase activity.\n",
      "Score: 2.4594\n",
      "\n",
      "Source: 1126\n",
      "Snippet: It was assumed, however, that some represented atypical clinical forms of EBV infection and that timing of specimen collection was a factor in explaining the paucity of Downey cells.\n",
      "Score: 2.3946\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_path = \"/Users/onurcanmemis/Desktop/Lectures/Information_Retrieval/Project/ir-bioasq/main_articles_head1000.csv\"\n",
    "\n",
    "# Define the query\n",
    "query = \"Effects of interferon on viral infections\"\n",
    "\n",
    "# Initialize the BM25 model\n",
    "bm25_model = BM25ModelWithPandas()\n",
    "\n",
    "# Retrieve top documents and snippets\n",
    "top_documents, top_snippets = bm25_model.get_relevant_documents_and_snippets(\n",
    "    query=query, file_path=file_path, top_n_docs=10, top_n_snippets=10\n",
    ")\n",
    "\n",
    "# Print the top documents\n",
    "print(\"\\nTop Documents:\")\n",
    "for _, doc in top_documents.iterrows():\n",
    "    print(f\"PMC ID: {doc['pmid']}, Score: {doc['score']:.4f}\")\n",
    "\n",
    "# Print the top snippets\n",
    "print(\"\\nTop Snippets:\")\n",
    "for snippet in top_snippets:\n",
    "    print(f\"Source: {snippet['source']}\")\n",
    "    print(f\"Snippet: {snippet['text']}\")\n",
    "    print(f\"Score: {snippet['score']:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BM25S- BM25 with Sparse Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BM25SDocumentRetriever:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initializes the BM25SnippetRetriever with the dataset file path.\n",
    "        \"\"\"\n",
    "        self.df = None\n",
    "        self.retriever = None\n",
    "        self.corpus_tokens = None\n",
    "\n",
    "    def load_and_preprocess_documents(self, file_path):\n",
    "        \"\"\"\n",
    "        Loads the dataset and preprocesses the text.\n",
    "        \"\"\"\n",
    "        print(\"Loading dataset...\")\n",
    "        self.df = pd.read_csv(file_path)\n",
    "        self.df[\"text\"] = self.df[\"title\"] + \" \" + self.df[\"abstract\"]\n",
    "        self.corpus_tokens = tokenize(self.df[\"text\"].tolist())\n",
    "\n",
    "    def build_corpus_index(self):\n",
    "        \"\"\"\n",
    "        Initializes the BM25 retriever and indexes the tokenized corpus.\n",
    "        \"\"\"\n",
    "        print(\"Building corpus index...\")\n",
    "        self.retriever = BM25()\n",
    "        self.retriever.index(self.corpus_tokens)\n",
    "\n",
    "    def retrieve_top_documents(self, query, k=10):\n",
    "        \"\"\"\n",
    "        Retrieves the top-k most relevant documents for the given query.\n",
    "        \"\"\"\n",
    "        print(\"Retrieving top documents...\")\n",
    "        query_tokens = tokenize(query)\n",
    "        docs, scores = self.retriever.retrieve(query_tokens, k=k)\n",
    "\n",
    "        # Map document indices back to the dataset\n",
    "        top_docs_indices = docs[0]\n",
    "        top_docs_scores = scores[0]\n",
    "\n",
    "        # Extract the top documents with their scores\n",
    "        top_documents = [\n",
    "            {\n",
    "                \"text\": self.df.iloc[idx][\"text\"],\n",
    "                \"score\": score,\n",
    "                \"pmid\": self.df.iloc[idx][\"pmid\"],\n",
    "            }\n",
    "            for idx, score in zip(top_docs_indices, top_docs_scores)\n",
    "        ]\n",
    "        return top_documents\n",
    "\n",
    "    def retrieve_top_snippets(self, query, top_documents, k=10):\n",
    "        \"\"\"\n",
    "        Retrieves the top-k most relevant snippets globally from the given top documents.\n",
    "        \"\"\"\n",
    "        print(\"Retrieving top snippets...\")\n",
    "        query_tokens = tokenize(query)\n",
    "\n",
    "        # Consolidate all snippets with document IDs\n",
    "        all_snippets = []\n",
    "        for doc in top_documents:\n",
    "            sentences = sent_tokenize(\n",
    "                doc[\"text\"]\n",
    "            )  # Split the document into sentences (snippets)\n",
    "            for sentence in sentences:\n",
    "                all_snippets.append({\"text\": sentence, \"source\": doc[\"pmid\"]})\n",
    "\n",
    "        # Tokenize all snippets\n",
    "        snippet_tokens = tokenize([snippet[\"text\"] for snippet in all_snippets])\n",
    "\n",
    "        # Re-index the BM25 retriever with snippets\n",
    "        self.retriever.index(snippet_tokens)\n",
    "\n",
    "        # Retrieve the top k most relevant snippets globally\n",
    "        snippet_docs, snippet_scores = self.retriever.retrieve(query_tokens, k=k)\n",
    "\n",
    "        # Extract the top k snippets with scores and source document IDs\n",
    "        top_snippets = [\n",
    "            {\n",
    "                \"text\": all_snippets[idx][\"text\"],\n",
    "                \"score\": snippet_scores[0, i],\n",
    "                \"source\": all_snippets[idx][\"source\"],\n",
    "            }\n",
    "            for i, idx in enumerate(snippet_docs[0])\n",
    "        ]\n",
    "        return top_snippets\n",
    "\n",
    "    def get_relevant_documents_and_snippets(\n",
    "        self, query, file_path, top_n_docs=10, top_n_snippets=10\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Main method to retrieve top documents and top snippets for a given query.\n",
    "        \"\"\"\n",
    "        # Load the dataset and build the index\n",
    "        self.load_and_preprocess_documents(file_path)\n",
    "        self.build_corpus_index()\n",
    "\n",
    "        # Retrieve top documents\n",
    "        top_documents = self.retrieve_top_documents(query, k=top_n_docs)\n",
    "\n",
    "        # Retrieve top snippets\n",
    "        top_snippets = self.retrieve_top_snippets(\n",
    "            query, top_documents, k=top_n_snippets\n",
    "        )\n",
    "\n",
    "        return top_documents, top_snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building corpus index...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving top documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving top snippets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 Snippets:\n",
      "Source Document: 884\n",
      "Snippet: Comparative study of virological infections in asthmatic and nonasthmatic children.\n",
      "Score: 1.39\n",
      "--------------------------------------------------------------------------------\n",
      "Source Document: 331\n",
      "Snippet: Thus, pneumococci exert several dose-dependent thromboplastic effects: (i) release of platelet thromboplastic substances; (ii) a direct thromboplastic effect; and (iii) release of polymorphonuclear coagulant.\n",
      "Score: 1.36\n",
      "--------------------------------------------------------------------------------\n",
      "Source Document: 1604\n",
      "Snippet: The significance of mosquito longevity and blood-feeding behaviour in the dynamics of arbovirus infections.\n",
      "Score: 1.29\n",
      "--------------------------------------------------------------------------------\n",
      "Source Document: 1468\n",
      "Snippet: The mixtures of viral fragments exhibited an increased deacetylase activity.\n",
      "Score: 1.23\n",
      "--------------------------------------------------------------------------------\n",
      "Source Document: 1468\n",
      "Snippet: Amongst the viral components, these structures showed the highest specific deacetylase activity.\n",
      "Score: 1.14\n",
      "--------------------------------------------------------------------------------\n",
      "Source Document: 1629\n",
      "Snippet: An association between viral hepatitis and two rheumatic disease syndromes has been observed.\n",
      "Score: 1.06\n",
      "--------------------------------------------------------------------------------\n",
      "Source Document: 331\n",
      "Snippet: Infections due to Streptococcus pneumoniae and products from the organism have been associated with alterations in blood clotting and function of platelets.\n",
      "Score: 1.06\n",
      "--------------------------------------------------------------------------------\n",
      "Source Document: 2143\n",
      "Snippet: It is postulated that the physicochemical alterations in the aqueous environment significantly affecting the stability of interferon operate by producing changes in the size and/or conformation of interferon molecules.\n",
      "Score: 1.02\n",
      "--------------------------------------------------------------------------------\n",
      "Source Document: 1604\n",
      "Snippet: Mosquito longevity and blood-feeding behaviour are very important but neglected factors in the dynamics of arbovirus infections as changes in them affect transmission rates exponentially.\n",
      "Score: 0.97\n",
      "--------------------------------------------------------------------------------\n",
      "Source Document: 2143\n",
      "Snippet: The influence of physicochemical factors on the thermal inactivation of murine interferon.\n",
      "Score: 0.96\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Top 10 Documents:\n",
      "PMC ID: 2143, Score: 5.13\n",
      "Text: The influence of physicochemical factors on the thermal inactivation of murine interferon. The degradation of biological activity of virus-induced murine interferon was determined in linear nonisother...\n",
      "--------------------------------------------------------------------------------\n",
      "PMC ID: 1990, Score: 4.91\n",
      "Text: Correlation between molecular size and interferon- inducing activity of poly I:C. Electron microscopy showed that commerical poly I: C consisted of molecules varying in length from less than 0.05 nm t...\n",
      "--------------------------------------------------------------------------------\n",
      "PMC ID: 1126, Score: 3.54\n",
      "Text: The specificity of heterophil antibodies in patients and healthy donors with no or minimal signs of infectious mononucleosis. Over several years sera were collected from 14 heterophil-positive student...\n",
      "--------------------------------------------------------------------------------\n",
      "PMC ID: 1604, Score: 2.76\n",
      "Text: The significance of mosquito longevity and blood-feeding behaviour in the dynamics of arbovirus infections. Mosquito longevity and blood-feeding behaviour are very important but neglected factors in t...\n",
      "--------------------------------------------------------------------------------\n",
      "PMC ID: 331, Score: 2.65\n",
      "Text: Effect of pneumococci on blood clotting, platelets, and polymorphonuclear leukocytes. Infections due to Streptococcus pneumoniae and products from the organism have been associated with alterations in...\n",
      "--------------------------------------------------------------------------------\n",
      "PMC ID: 938, Score: 2.50\n",
      "Text: The virus hypothesis in systemic lupus erythematosus. Type-C viruses are currently the prime etiologic candidates in systemic lupus erythematosus. On the basis of knowledge gained from studies of expe...\n",
      "--------------------------------------------------------------------------------\n",
      "PMC ID: 1629, Score: 2.40\n",
      "Text: Polyarthritis, polyarteritis and hepatitis B. An association between viral hepatitis and two rheumatic disease syndromes has been observed. Twenty-nine patients manifested a transient polyarthritis, s...\n",
      "--------------------------------------------------------------------------------\n",
      "PMC ID: 1628, Score: 2.40\n",
      "Text: Vasculitis with hepatitis B antigenemia: long-term observation in nine patients. The development of generalized necrotizing vasculitis in association with hepatitis B antigenemia is the first example ...\n",
      "--------------------------------------------------------------------------------\n",
      "PMC ID: 884, Score: 2.34\n",
      "Text: Comparative study of virological infections in asthmatic and nonasthmatic children. The author shows complex analyses: clinical, laboratory, X-rays, bronchoscopical, bronchographical and measuring lun...\n",
      "--------------------------------------------------------------------------------\n",
      "PMC ID: 1468, Score: 2.19\n",
      "Text: Disruption of Vi bacteriophage III and localization of its deacetylase activity. It has been shown that particles of Vi bacteriophage III catalyse deacetylation of O-acetyl pectic (polygalacturonic) a...\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "file_path = \"/Users/onurcanmemis/Desktop/Lectures/Information_Retrieval/Project/ir-bioasq/main_articles_head1000.csv\"\n",
    "query = \"Effects of interferon on viral infections\"\n",
    "\n",
    "bm25_model = BM25SDocumentRetriever()\n",
    "top_documents, top_snippets = bm25_model.get_relevant_documents_and_snippets(\n",
    "    query=query, file_path=file_path, top_n_docs=10, top_n_snippets=10\n",
    ")\n",
    "print(\"\\nTop 10 Snippets:\")\n",
    "for snippet in top_snippets:\n",
    "    print(f\"Source Document: {snippet['source']}\")\n",
    "    print(f\"Snippet: {snippet['text']}\")\n",
    "    print(f\"Score: {snippet['score']:.2f}\")\n",
    "    print(\"-\" * 80)\n",
    "# Print top documents\n",
    "print(\"\\nTop 10 Documents:\")\n",
    "for doc in top_documents:\n",
    "    print(f\"PMC ID: {doc['pmid']}, Score: {doc['score']:.2f}\")\n",
    "    print(f\"Text: {doc['text'][:200]}...\")  # Print a snippet of the document text\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic Retrieval Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic IR Model- With Speed Ups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SemanticRetrievalModelWithPandasOptimized:\n",
    "    def __init__(\n",
    "        self, model_name=\"sentence-transformers/paraphrase-MiniLM-L3-v2\", use_gpu=True\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize the semantic model using a pre-trained Sentence-BERT model.\n",
    "        \"\"\"\n",
    "        device = \"cuda\" if use_gpu and torch.cuda.is_available() else \"cpu\"\n",
    "        self.embedding_model = SentenceTransformer(model_name, device=device)\n",
    "\n",
    "    def preprocess_documents(self, file_path):\n",
    "        \"\"\"\n",
    "        Loads and preprocesses documents using Pandas. Assumes the CSV file has columns `pmid`, `title`, and `abstract`.\n",
    "        \"\"\"\n",
    "        print(f\"Loading documents from {file_path}\")\n",
    "        df = pd.read_csv(file_path)\n",
    "        df.dropna(\n",
    "            subset=[\"pmid\", \"title\", \"abstract\"], inplace=True\n",
    "        )  # Drop rows with missing values\n",
    "\n",
    "        # Combine title and abstract into a single text column\n",
    "        df[\"text\"] = df[\"title\"] + \" \" + df[\"abstract\"]\n",
    "        return df\n",
    "\n",
    "    def encode_batch_text(self, texts):\n",
    "        \"\"\"\n",
    "        Encodes a batch of texts into embeddings using the Sentence-BERT model.\n",
    "        \"\"\"\n",
    "        embeddings = self.embedding_model.encode(\n",
    "            texts, convert_to_tensor=True, batch_size=32\n",
    "        )\n",
    "        return embeddings.cpu()  # Ensure embeddings are moved to CPU\n",
    "\n",
    "    def build_faiss_index(self, embeddings):\n",
    "        \"\"\"\n",
    "        Builds a FAISS index for approximate nearest neighbor search.\n",
    "        \"\"\"\n",
    "        embeddings_np = np.array(embeddings)  # Convert embeddings to NumPy array\n",
    "        d = embeddings_np.shape[1]  # Dimension of embeddings\n",
    "        index = faiss.IndexFlatL2(d)\n",
    "        index.add(embeddings_np)  # Add embeddings to the index\n",
    "        return index\n",
    "\n",
    "    def search_faiss_index(self, index, query_embedding, top_k=10):\n",
    "        \"\"\"\n",
    "        Searches the FAISS index for the top-k most similar embeddings.\n",
    "        \"\"\"\n",
    "        query_embedding_np = (\n",
    "            query_embedding.cpu().numpy().reshape(1, -1)\n",
    "        )  # Move query embedding to CPU\n",
    "        distances, indices = index.search(query_embedding_np, top_k)\n",
    "        return distances[0], indices[0]\n",
    "\n",
    "    def filter_documents(self, query, documents, embeddings, top_n_docs=10):\n",
    "        \"\"\"\n",
    "        Filters documents using approximate semantic similarity.\n",
    "        \"\"\"\n",
    "        query_embedding = self.encode_batch_text([query])\n",
    "        index = self.build_faiss_index(embeddings)\n",
    "        distances, indices = self.search_faiss_index(index, query_embedding, top_n_docs)\n",
    "\n",
    "        top_documents = [\n",
    "            {\n",
    "                \"pmc_id\": documents.iloc[i][\"pmid\"],\n",
    "                \"text\": documents.iloc[i][\"text\"],\n",
    "                \"score\": 1\n",
    "                / (1 + distances[idx]),  # Inverse scaling to normalize distance\n",
    "                \"url\": f\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC{documents.iloc[i]['pmid']}/\",\n",
    "            }\n",
    "            for idx, i in enumerate(indices)\n",
    "        ]\n",
    "        return top_documents, query_embedding\n",
    "\n",
    "    def rank_snippets(self, query_embedding, top_documents, top_n_snippets=10):\n",
    "        \"\"\"\n",
    "        Ranks snippets globally based on semantic similarity.\n",
    "        \"\"\"\n",
    "        snippets = []\n",
    "        for doc in top_documents:\n",
    "            sentences = sent_tokenize(doc[\"text\"])  # Split the document into sentences\n",
    "            snippet_embeddings = self.encode_batch_text(sentences)\n",
    "            snippet_scores = cosine_similarity(\n",
    "                query_embedding.cpu().numpy(), snippet_embeddings.cpu().numpy()\n",
    "            )[0]\n",
    "\n",
    "            for i, sentence in enumerate(sentences):\n",
    "                snippets.append(\n",
    "                    {\n",
    "                        \"text\": sentence,\n",
    "                        \"source\": doc[\"pmc_id\"],\n",
    "                        \"score\": snippet_scores[i],\n",
    "                    }\n",
    "                )\n",
    "\n",
    "        # Sort snippets globally by score\n",
    "        top_snippets = sorted(snippets, key=lambda x: x[\"score\"], reverse=True)[\n",
    "            :top_n_snippets\n",
    "        ]\n",
    "        return top_snippets\n",
    "\n",
    "    def get_relevant_documents_and_snippets(\n",
    "        self, query, file_path, top_n_docs=10, top_n_snippets=10\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Retrieves top N most relevant documents and globally ranks snippets from them.\n",
    "        \"\"\"\n",
    "        # Load documents with Pandas\n",
    "        df = self.preprocess_documents(file_path)\n",
    "\n",
    "        if len(df) == 0:\n",
    "            print(\"No valid documents found.\")\n",
    "            return [], []\n",
    "\n",
    "        # Encode document embeddings in batches\n",
    "        print(\"Encoding document embeddings...\")\n",
    "        embeddings = np.array(\n",
    "            [\n",
    "                embedding.cpu().numpy()\n",
    "                for embedding in self.encode_batch_text(df[\"text\"].tolist())\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Filter top documents using semantic similarity\n",
    "        print(\"Filtering top documents...\")\n",
    "        top_documents, query_embedding = self.filter_documents(\n",
    "            query, df, embeddings, top_n_docs=top_n_docs\n",
    "        )\n",
    "\n",
    "        # Rank snippets globally\n",
    "        print(\"Ranking snippets globally...\")\n",
    "        top_snippets = self.rank_snippets(\n",
    "            query_embedding, top_documents, top_n_snippets=top_n_snippets\n",
    "        )\n",
    "\n",
    "        return top_documents, top_snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading documents from /Users/onurcanmemis/Desktop/Lectures/Information_Retrieval/Project/ir-bioasq/main_articles_head1000.csv\n",
      "Encoding document embeddings...\n",
      "Filtering top documents...\n",
      "Ranking snippets globally...\n",
      "\n",
      "Top 10 Documents:\n",
      "PMC ID: 1295, URL: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1295/, Score: 0.0398\n",
      "PMC ID: 2143, URL: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2143/, Score: 0.0397\n",
      "PMC ID: 1628, URL: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1628/, Score: 0.0389\n",
      "PMC ID: 1990, URL: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1990/, Score: 0.0379\n",
      "PMC ID: 1996, URL: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1996/, Score: 0.0379\n",
      "PMC ID: 725, URL: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC725/, Score: 0.0373\n",
      "PMC ID: 1801, URL: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1801/, Score: 0.0371\n",
      "PMC ID: 2396, URL: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2396/, Score: 0.0371\n",
      "PMC ID: 1296, URL: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1296/, Score: 0.0364\n",
      "PMC ID: 1145, URL: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1145/, Score: 0.0364\n",
      "\n",
      "Top 10 Snippets:\n",
      "Source: https://www.ncbi.nlm.nih.gov/pmc/articles/2143/\n",
      "Snippet: It is postulated that the physicochemical alterations in the aqueous environment significantly affecting the stability of interferon operate by producing changes in the size and/or conformation of interferon molecules.\n",
      "Score: 0.4390\n",
      "\n",
      "Source: https://www.ncbi.nlm.nih.gov/pmc/articles/2143/\n",
      "Snippet: Interferon heated to 80degree C could not be reactivated at 40degree C or 55degree C. Interferon of higher apparent molecular weight was more heat-stable than that with lower apparent molecular weight.\n",
      "Score: 0.4115\n",
      "\n",
      "Source: https://www.ncbi.nlm.nih.gov/pmc/articles/1295/\n",
      "Snippet: Prolonged survival of weakly incompatible skin allografts in mice (across the barrier presented by the MSA) can be induced by pretreating the recipients not only with a specific anti-MSA serum (obtained on day 5 after a single MSA-incompatible skin graft) but also be means of control serum obtained in a similar way from the recipients of fully compatible (syngeneic) skin grafts.\n",
      "Score: 0.4006\n",
      "\n",
      "Source: https://www.ncbi.nlm.nih.gov/pmc/articles/2143/\n",
      "Snippet: The rate of cooling of heated interferon significantly influenced its residual activity.\n",
      "Score: 0.3959\n",
      "\n",
      "Source: https://www.ncbi.nlm.nih.gov/pmc/articles/2143/\n",
      "Snippet: A model is proposed that relates thermal inactivation to different possible molecular states of interferon.\n",
      "Score: 0.3583\n",
      "\n",
      "Source: https://www.ncbi.nlm.nih.gov/pmc/articles/1628/\n",
      "Snippet: Vasculitis with hepatitis B antigenemia: long-term observation in nine patients.\n",
      "Score: 0.3560\n",
      "\n",
      "Source: https://www.ncbi.nlm.nih.gov/pmc/articles/1628/\n",
      "Snippet: The natural history of the disease is emphasized and the manifestations of patients with vasculitis who carry hepatitis B antigen are compared with those of vasculitis patients who are antigen negative.\n",
      "Score: 0.3497\n",
      "\n",
      "Source: https://www.ncbi.nlm.nih.gov/pmc/articles/2396/\n",
      "Snippet: A solid-phase system was set up, using antisera to cortisol-21-BSA conjucates coupled to CNBr-activated cellulose.\n",
      "Score: 0.3390\n",
      "\n",
      "Source: https://www.ncbi.nlm.nih.gov/pmc/articles/2143/\n",
      "Snippet: The stabilizing effect of pH during heating on interferon in solution was greatest at low pH, such that pH 2 greater than pH 5 greater than pH 7 greater than or equal to pH 9; freeze-dried preparations of interferon were also more heat-stable at acid pH than at neutral pH.\n",
      "Score: 0.3344\n",
      "\n",
      "Source: https://www.ncbi.nlm.nih.gov/pmc/articles/1628/\n",
      "Snippet: This report reviews the experience in nine biopsy-proven cases of hepatitis B-associated necrotizing vasculitis followed for up to six years.\n",
      "Score: 0.3193\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "model = SemanticRetrievalModelWithPandasOptimized()\n",
    "\n",
    "# Define the query and CSV file path\n",
    "query = \"Multiple sclerosis treatments using interferon\"\n",
    "file_path = \"/Users/onurcanmemis/Desktop/Lectures/Information_Retrieval/Project/ir-bioasq/main_articles_head1000.csv\"\n",
    "\n",
    "# Retrieve top documents and snippets\n",
    "top_documents, top_snippets = model.get_relevant_documents_and_snippets(\n",
    "    query=query, file_path=file_path, top_n_docs=10, top_n_snippets=10\n",
    ")\n",
    "\n",
    "# Print the top 10 documents\n",
    "print(\"\\nTop 10 Documents:\")\n",
    "for doc in top_documents:\n",
    "    print(f\"PMC ID: {doc['pmc_id']}, URL: {doc['url']}, Score: {doc['score']:.4f}\")\n",
    "\n",
    "# Print the top 10 snippets\n",
    "print(\"\\nTop 10 Snippets:\")\n",
    "for snippet in top_snippets:\n",
    "    print(f\"Source: https://www.ncbi.nlm.nih.gov/pmc/articles/{snippet['source']}/\")\n",
    "    print(f\"Snippet: {snippet['text']}\")\n",
    "    print(f\"Score: {snippet['score']:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Commplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating QuerySpecificTFIDFModelLogarithmic...\n",
      "Loading documents from /Users/onurcanmemis/Desktop/Lectures/Information_Retrieval/Project/ir-bioasq/main_articles_head1000.csv\n",
      "Building TF-IDF model...\n",
      "Calculating relevance scores...\n",
      "Retrieving top documents...\n",
      "Ranking snippets globally...\n",
      "Evaluating QuerySpecificTFIDFModelRaw...\n",
      "Loading documents from /Users/onurcanmemis/Desktop/Lectures/Information_Retrieval/Project/ir-bioasq/main_articles_head1000.csv\n",
      "Building TF-IDF model...\n",
      "Calculating relevance scores...\n",
      "Retrieving top documents...\n",
      "Ranking snippets globally...\n",
      "Evaluating QuerySpecificTFIDFModelAugmented...\n",
      "Loading documents from /Users/onurcanmemis/Desktop/Lectures/Information_Retrieval/Project/ir-bioasq/main_articles_head1000.csv\n",
      "Building TF-IDF model...\n",
      "Calculating relevance scores...\n",
      "Retrieving top documents...\n",
      "Ranking snippets globally...\n",
      "Evaluating BM25ModelWithPandas...\n",
      "Loading documents from /Users/onurcanmemis/Desktop/Lectures/Information_Retrieval/Project/ir-bioasq/main_articles_head1000.csv\n",
      "Evaluating SemanticRetrievalModelWithPandasOptimized...\n",
      "Loading documents from /Users/onurcanmemis/Desktop/Lectures/Information_Retrieval/Project/ir-bioasq/main_articles_head1000.csv\n",
      "Encoding document embeddings...\n",
      "Filtering top documents...\n",
      "Ranking snippets globally...\n",
      "Evaluating BM25SparseMatrixVersion...\n",
      "Loading dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building corpus index...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving top documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 Documents:\n",
      "PMC ID: 2143, Score: 6.41\n",
      "Text: The influence of physicochemical factors on the thermal inactivation of murine interferon. The degradation of biological activity of virus-induced murine interferon was determined in linear nonisother...\n",
      "--------------------------------------------------------------------------------\n",
      "PMC ID: 1990, Score: 4.91\n",
      "Text: Correlation between molecular size and interferon- inducing activity of poly I:C. Electron microscopy showed that commerical poly I: C consisted of molecules varying in length from less than 0.05 nm t...\n",
      "--------------------------------------------------------------------------------\n",
      "PMC ID: 537, Score: 2.77\n",
      "Text: Multiple cyclic nucleotide phosphodiesterases in rat kidney. Using DEAE-cellulose chromatography and Agarose gel filtration we have partially purified a low Km cyclic adenosine monophosphate (AMP) pho...\n",
      "--------------------------------------------------------------------------------\n",
      "PMC ID: 159, Score: 2.60\n",
      "Text: Serum lactate dehydrogenase activity ratios with different substrates. 1. The lactate dehydrogenase activity of 89 sera from patients suffering myocardial infarction and of 55 sera from patients with ...\n",
      "--------------------------------------------------------------------------------\n",
      "PMC ID: 377, Score: 2.45\n",
      "Text: Studies on cathepsins of rat liver lysosomes. II. Comparative studies on multiple forms of cathepsin A. The multiple forms of cathepsin A (AI, AII, and AIII) purified from the lysosome fraction of rat...\n",
      "--------------------------------------------------------------------------------\n",
      "PMC ID: 451, Score: 2.33\n",
      "Text: Hemoglobins and hemocyanins: comparative aspects of structure and function. Comparative studies of protein structure and function can be quite interesting by themselves, and even more interesting when...\n",
      "--------------------------------------------------------------------------------\n",
      "PMC ID: 1268, Score: 2.23\n",
      "Text: Polyadenylated RNA from Vicia faba meristematic root cells. Localization and size estimation of the poly (A) segment. After incubating root apices from two-day-old bean seedlings with [3H] adenine the...\n",
      "--------------------------------------------------------------------------------\n",
      "PMC ID: 907, Score: 2.17\n",
      "Text: Congenital malformations of the central nervous system produced by narcotic analgesics in the hamster. Maternal dose--fetal teratogenic response data were obtained for a variety of narcotic and relate...\n",
      "--------------------------------------------------------------------------------\n",
      "PMC ID: 1459, Score: 2.14\n",
      "Text: Water regulation by a presumptive hormone contained in identified neurosecretory cell R15 of Aplysia. Injection of an homogenate of identified neuron R15 into the hemocele of Aplysia produced a weight...\n",
      "--------------------------------------------------------------------------------\n",
      "PMC ID: 412, Score: 2.11\n",
      "Text: Stimulation of lactic acid production in chick embryo fibroblasts by serum and high pH in the absence of external glucose. Lactic acid production by chick embryo fibroblasts occurs in the absence of e...\n",
      "--------------------------------------------------------------------------------\n",
      "Retrieving top snippets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 Snippets:\n",
      "Source Document: 2143\n",
      "Snippet: The degradation of biological activity of virus-induced murine interferon was determined in linear nonisothermal and multiple isothermal tests.\n",
      "Score: 1.69\n",
      "--------------------------------------------------------------------------------\n",
      "Source Document: 1268\n",
      "Snippet: The alterations of the RNA molecules due to the various treatments were monitored by sucrose density gradients.\n",
      "Score: 1.44\n",
      "--------------------------------------------------------------------------------\n",
      "Source Document: 451\n",
      "Snippet: Our studies suggest the possibility of using Limulus hemocyanin and other hemocyanins as structural homologs and analogs of more complex macromolecular arrays.\n",
      "Score: 1.23\n",
      "--------------------------------------------------------------------------------\n",
      "Source Document: 377\n",
      "Snippet: Comparative studies on multiple forms of cathepsin A.\n",
      "Score: 1.18\n",
      "--------------------------------------------------------------------------------\n",
      "Source Document: 1459\n",
      "Snippet: The results of bioassays of R15 extracts subjected to different treatments are consistent with the hypothesis that activity is due to one or more stable polypeptides of relatively low molecular weight.\n",
      "Score: 1.13\n",
      "--------------------------------------------------------------------------------\n",
      "Source Document: 537\n",
      "Snippet: Multiple cyclic nucleotide phosphodiesterases in rat kidney.\n",
      "Score: 1.13\n",
      "--------------------------------------------------------------------------------\n",
      "Source Document: 412\n",
      "Snippet: The results suggest that treatments which stimulate cell multiplication also activate those enzymatic pathways which convert amino acids to pyruvic and thence to lactic acid.\n",
      "Score: 1.11\n",
      "--------------------------------------------------------------------------------\n",
      "Source Document: 2143\n",
      "Snippet: It is postulated that the physicochemical alterations in the aqueous environment significantly affecting the stability of interferon operate by producing changes in the size and/or conformation of interferon molecules.\n",
      "Score: 1.06\n",
      "--------------------------------------------------------------------------------\n",
      "Source Document: 537\n",
      "Snippet: Using DEAE-cellulose chromatography and Agarose gel filtration we have partially purified a low Km cyclic adenosine monophosphate (AMP) phosphodiesterase from the 100,000 X g supernatant of rat kidneys.\n",
      "Score: 1.00\n",
      "--------------------------------------------------------------------------------\n",
      "Source Document: 2143\n",
      "Snippet: The influence of physicochemical factors on the thermal inactivation of murine interferon.\n",
      "Score: 0.99\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Comparison Results:\n",
      "Model: QuerySpecificTFIDFModelLogarithmic, Time Taken: 0.52 seconds\n",
      "Model: QuerySpecificTFIDFModelRaw, Time Taken: 1.38 seconds\n",
      "Model: QuerySpecificTFIDFModelAugmented, Time Taken: 1.36 seconds\n",
      "Model: BM25ModelWithPandas, Time Taken: 0.34 seconds\n",
      "Model: SemanticRetrievalModelWithPandasOptimized, Time Taken: 7.94 seconds\n",
      "Model: BM25SparseMatrixVersion, Time Taken: 0.22 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Path to the CSV file\n",
    "csv_file_path = \"/Users/onurcanmemis/Desktop/Lectures/Information_Retrieval/Project/ir-bioasq/main_articles_head1000.csv\"\n",
    "\n",
    "# Query to use for comparison\n",
    "query = \"Multiple sclerosis treatments using interferon\"\n",
    "\n",
    "# Number of documents and snippets to retrieve\n",
    "top_n_docs = 10\n",
    "top_n_snippets = 10\n",
    "\n",
    "# List of models to compare\n",
    "models = [\n",
    "    {\n",
    "        \"name\": \"QuerySpecificTFIDFModelLogarithmic\",\n",
    "        \"class\": QuerySpecificTFIDFModelLogarithmic,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"QuerySpecificTFIDFModelRaw\",\n",
    "        \"class\": QuerySpecificTFIDFModelRaw,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"QuerySpecificTFIDFModelAugmented\",\n",
    "        \"class\": QuerySpecificTFIDFModelAugmented,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"BM25ModelWithPandas\",\n",
    "        \"class\": BM25ModelWithPandas,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"SemanticRetrievalModelWithPandasOptimized\",\n",
    "        \"class\": SemanticRetrievalModelWithPandasOptimized,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"BM25SparseMatrixVersion\",\n",
    "        \"class\": BM25SDocumentRetriever,\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "# Function to measure execution time of a model\n",
    "def measure_execution_time(\n",
    "    model_class, csv_file_path, query, top_n_docs, top_n_snippets\n",
    "):\n",
    "    model = model_class()  # Instantiate the model\n",
    "    start_time = time.time()\n",
    "    model.get_relevant_documents_and_snippets(\n",
    "        query, csv_file_path, top_n_docs=top_n_docs, top_n_snippets=top_n_snippets\n",
    "    )\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    return elapsed_time\n",
    "\n",
    "\n",
    "# Compare the models\n",
    "results = []\n",
    "for model_info in models:\n",
    "    model_name = model_info[\"name\"]\n",
    "    model_class = model_info[\"class\"]\n",
    "    print(f\"Evaluating {model_name}...\")\n",
    "    elapsed_time = measure_execution_time(\n",
    "        model_class, csv_file_path, query, top_n_docs, top_n_snippets\n",
    "    )\n",
    "    results.append({\"Model\": model_name, \"Time (seconds)\": elapsed_time})\n",
    "\n",
    "# Print results\n",
    "print(\"\\nComparison Results:\")\n",
    "for result in results:\n",
    "    print(\n",
    "        f\"Model: {result['Model']}, Time Taken: {result['Time (seconds)']:.2f} seconds\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_ids(url_list):\n",
    "    for url in url_list:\n",
    "        yield url.rsplit(\"/\", 1)[-1]  # Extract PubMed ID from the URL\n",
    "\n",
    "\n",
    "def calculate_macro_metrics(retrieved_docs_list, golden_docs_list):\n",
    "    \"\"\"\n",
    "    Calculate Macro-Averaged Precision, Recall, and F1-Score for multiple queries.\n",
    "\n",
    "    Parameters:\n",
    "    retrieved_docs_list (list of lists): A list where each element is a list of retrieved document URLs for a query.\n",
    "    golden_docs_list (list of lists): A list where each element is a list of golden document URLs for a query.\n",
    "\n",
    "    Returns:\n",
    "    dict: Macro precision, recall, and F1-score.\n",
    "    \"\"\"\n",
    "    # Initialize lists to store per-query metrics\n",
    "    macro_precision = []\n",
    "    macro_recall = []\n",
    "    macro_f1 = []\n",
    "\n",
    "    for retrieved_docs, golden_docs in zip(retrieved_docs_list, golden_docs_list):\n",
    "        # Convert lists to sets for efficient comparison\n",
    "        retrieved_set = set(extract_ids(retrieved_docs))\n",
    "        golden_set = set(extract_ids(golden_docs))\n",
    "\n",
    "        # Compute intersection\n",
    "        intersection = retrieved_set & golden_set\n",
    "\n",
    "        # Metrics for the current query\n",
    "        precision = len(intersection) / len(retrieved_set) if retrieved_set else 0\n",
    "        recall = len(intersection) / len(golden_set) if golden_set else 0\n",
    "        f1 = (\n",
    "            (2 * precision * recall) / (precision + recall)\n",
    "            if (precision + recall) > 0\n",
    "            else 0\n",
    "        )\n",
    "\n",
    "        # Store the metrics for macro-averaging\n",
    "        macro_precision.append(precision)\n",
    "        macro_recall.append(recall)\n",
    "        macro_f1.append(f1)\n",
    "\n",
    "    # Macro-Averaged Metrics\n",
    "    macro_avg_precision = (\n",
    "        sum(macro_precision) / len(macro_precision) if macro_precision else 0\n",
    "    )\n",
    "    macro_avg_recall = sum(macro_recall) / len(macro_recall) if macro_recall else 0\n",
    "    macro_avg_f1 = sum(macro_f1) / len(macro_f1) if macro_f1 else 0\n",
    "\n",
    "    return {\n",
    "        \"macro_avg_precision\": macro_avg_precision,\n",
    "        \"macro_avg_recall\": macro_avg_recall,\n",
    "        \"macro_avg_f1\": macro_avg_f1,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logarithmic VSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the DocumentSimilarity object\n",
    "doc_sim = TF_IDF_Gensim_Log(method=\"lfu\")\n",
    "# Create the TF-IDF model and similarity index\n",
    "doc_sim.create_tfidf_model(df[\"processed_text\"])\n",
    "# Retrieve the most relevant documents for each query\n",
    "doc, snippets = doc_sim.get_most_relevant_documents(query_documents, top_n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'macro_avg_precision': 0.0058823529411764705,\n",
       " 'macro_avg_recall': 0.0019411764705882354,\n",
       " 'macro_avg_f1': 0.0029131652661064425}"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_macro_metrics(doc, query_df[\"golden_docs\"].to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Raw VSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the DocumentSimilarity object\n",
    "doc_sim = TF_IDF_Gensim_Raw(method=\"nfc\")\n",
    "# Create the TF-IDF model and similarity index\n",
    "doc_sim.create_tfidf_model(df[\"processed_text\"])\n",
    "# Retrieve the most relevant documents for each query\n",
    "doc, snippets = doc_sim.get_most_relevant_documents(query_documents, top_n=10)\n",
    "calculate_macro_metrics(doc, query_df[\"golden_docs\"].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_macro_metrics(doc, query_df[\"golden_docs\"].to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Augmented VSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the DocumentSimilarity object\n",
    "doc_sim = TF_IDF_Gensim_Augmented(method=\"afc\")\n",
    "# Create the TF-IDF model and similarity index\n",
    "doc_sim.create_tfidf_model(df[\"processed_text\"])\n",
    "# Retrieve the most relevant documents for each query\n",
    "doc, snippets = doc_sim.get_most_relevant_documents(query_documents, top_n=10)\n",
    "calculate_macro_metrics(doc, query_df[\"golden_docs\"].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_macro_metrics(doc, query_df[\"golden_docs\"].to_list())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/onurcanmemis/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/onurcanmemis/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/onurcanmemis/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import TfidfModel\n",
    "from gensim.similarities import SparseMatrixSimilarity\n",
    "from rank_bm25 import BM25Okapi  # BM25 library\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import faiss  # For approximate nearest neighbor search\n",
    "import torch\n",
    "from bm25s import tokenize, BM25\n",
    "\n",
    "# Download NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VSM Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Logarithmic\n",
    "> lfu\n",
    "* logarithmic frequency (l)\n",
    "* idf (f)\n",
    "* Pivoted unique normalization (u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuerySpecificTFIDFModelLogarithmic:\n",
    "    def __init__(self):\n",
    "        # Initialize stop words and lemmatizer\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.dictionary = None\n",
    "        self.tfidf_model = None\n",
    "        self.index = None\n",
    "\n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"\n",
    "        Preprocesses text by tokenizing, removing stopwords, and lemmatizing.\n",
    "        \"\"\"\n",
    "\n",
    "        ######## THIS PART IS CHANGED FROM word_tokenize to .split() it is 2x faster!!!\n",
    "        ############################\n",
    "\n",
    "        \n",
    "        tokens = text.lower().split()  # Tokenize and convert to lowercase\n",
    "        tokens = [word for word in tokens if word.isalnum() and word not in self.stop_words]  # Remove stop words and punctuation\n",
    "        tokens = [self.lemmatizer.lemmatize(word) for word in tokens]  # Apply lemmatization\n",
    "        return tokens\n",
    "\n",
    "    def load_and_preprocess_documents(self, file_path):\n",
    "        \"\"\"\n",
    "        Loads and preprocesses documents from a CSV file.\n",
    "        \"\"\"\n",
    "        print(f\"Loading documents from {file_path}\")\n",
    "        df = pd.read_csv(file_path)\n",
    "        df = df.dropna(subset=[\"pmid\", \"title\", \"abstract\"])  # Drop rows with missing values\n",
    "\n",
    "        # Combine title and abstract, and preprocess\n",
    "        df[\"raw_text\"] = df[\"title\"] + \" \" + df[\"abstract\"]\n",
    "        df[\"tokens\"] = df[\"raw_text\"].apply(self.preprocess_text)\n",
    "        return df\n",
    "\n",
    "    def build_tfidf_model(self, documents):\n",
    "        \"\"\"\n",
    "        Builds the TF-IDF model and similarity index using Gensim.\n",
    "        \"\"\"\n",
    "        print(\"Building TF-IDF model...\")\n",
    "        self.dictionary = Dictionary(documents[\"tokens\"])  # Create a Gensim dictionary\n",
    "        corpus = [self.dictionary.doc2bow(tokens) for tokens in documents[\"tokens\"]]  # Convert to bag-of-words format\n",
    "        self.tfidf_model = TfidfModel(corpus,smartirs='lfu')  # Build the TF-IDF model\n",
    "        self.index = SparseMatrixSimilarity(self.tfidf_model[corpus], num_features=len(self.dictionary))  # Build similarity index\n",
    "        return corpus\n",
    "\n",
    "    def calculate_relevance(self, query, corpus):\n",
    "        \"\"\"\n",
    "        Calculates relevance scores for the query against the corpus.\n",
    "        \"\"\"\n",
    "        print(\"Calculating relevance scores...\")\n",
    "        query_tokens = self.preprocess_text(query)\n",
    "        query_bow = self.dictionary.doc2bow(query_tokens)  # Convert query to bag-of-words\n",
    "        query_tfidf = self.tfidf_model[query_bow]  # Convert query to TF-IDF\n",
    "        similarities = self.index[query_tfidf]  # Compute similarities\n",
    "        return similarities\n",
    "\n",
    "    def rank_snippets(self, query, top_documents, top_n_snippets=10):\n",
    "        \"\"\"\n",
    "        Extracts and ranks snippets globally based on similarity to the query.\n",
    "        \"\"\"\n",
    "        print(\"Ranking snippets globally...\")\n",
    "        snippets = []\n",
    "        query_tokens = self.preprocess_text(query)\n",
    "\n",
    "        for _, doc in top_documents.iterrows():\n",
    "            pmid, text = doc[\"pmid\"], doc[\"raw_text\"]\n",
    "            sentences = sent_tokenize(text)\n",
    "            for sentence in sentences:\n",
    "                sentence_tokens = self.preprocess_text(sentence)\n",
    "                sentence_bow = self.dictionary.doc2bow(sentence_tokens)\n",
    "                sentence_tfidf = self.tfidf_model[sentence_bow]\n",
    "                snippet_score = sum(\n",
    "                    score for term_id, score in sentence_tfidf if term_id in [self.dictionary.token2id.get(token) for token in query_tokens]\n",
    "                )\n",
    "                snippets.append({\n",
    "                    \"text\": sentence,\n",
    "                    \"source\": pmid,\n",
    "                    \"score\": snippet_score,\n",
    "                })\n",
    "\n",
    "        # Sort snippets globally\n",
    "        top_snippets = sorted(snippets, key=lambda x: x[\"score\"], reverse=True)[:top_n_snippets]\n",
    "        return top_snippets\n",
    "\n",
    "    def get_relevant_documents_and_snippets(self, query, file_path, top_n_docs=10, top_n_snippets=10):\n",
    "        \"\"\"\n",
    "        Retrieves the top N relevant documents and globally ranked snippets.\n",
    "        \"\"\"\n",
    "        # Load and preprocess documents\n",
    "        documents = self.load_and_preprocess_documents(file_path)\n",
    "        if len(documents) == 0:\n",
    "            print(\"No valid documents found.\")\n",
    "            return [], []\n",
    "\n",
    "        # Build the TF-IDF model\n",
    "        corpus = self.build_tfidf_model(documents)\n",
    "\n",
    "        # Calculate relevance scores\n",
    "        relevance_scores = self.calculate_relevance(query, corpus)\n",
    "\n",
    "        # Retrieve the indices of the top N documents\n",
    "        print(\"Retrieving top documents...\")\n",
    "        top_indices = np.argsort(relevance_scores)[-top_n_docs:][::-1]  # Get indices of top N scores in descending order\n",
    "\n",
    "        # Create a DataFrame with the top N documents\n",
    "        top_documents = documents.iloc[top_indices].copy()\n",
    "        top_documents[\"score\"] = [relevance_scores[idx] for idx in top_indices]\n",
    "\n",
    "        # Rank snippets globally\n",
    "        top_snippets = self.rank_snippets(query, top_documents, top_n_snippets)\n",
    "\n",
    "        return top_documents, top_snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading documents from /Users/onurcanmemis/Desktop/Lectures/Information_Retrieval/Project/ir-bioasq/main_articles_head1000.csv\n",
      "Building TF-IDF model...\n",
      "Calculating relevance scores...\n",
      "Retrieving top documents...\n",
      "Ranking snippets globally...\n",
      "Top Documents:\n",
      "PMID: 2143, Score: 0.3345\n",
      "PMID: 1126, Score: 0.1153\n",
      "PMID: 1990, Score: 0.1044\n",
      "PMID: 2142, Score: 0.0994\n",
      "PMID: 1629, Score: 0.0837\n",
      "PMID: 1468, Score: 0.0811\n",
      "PMID: 938, Score: 0.0750\n",
      "PMID: 884, Score: 0.0728\n",
      "PMID: 2145, Score: 0.0690\n",
      "PMID: 1792, Score: 0.0619\n",
      "\n",
      "Top Snippets:\n",
      "Snippet: The stabilizing effect of pH during heating on interferon in solution was greatest at low pH, such that pH 2 greater than pH 5 greater than pH 7 greater than or equal to pH 9; freeze-dried preparations of interferon were also more heat-stable at acid pH than at neutral pH., Score: 0.4212\n",
      "Snippet: Interferon heated to 80degree C could not be reactivated at 40degree C or 55degree C. Interferon of higher apparent molecular weight was more heat-stable than that with lower apparent molecular weight., Score: 0.3944\n",
      "Snippet: It is postulated that the physicochemical alterations in the aqueous environment significantly affecting the stability of interferon operate by producing changes in the size and/or conformation of interferon molecules., Score: 0.3923\n",
      "Snippet: Rapid cooling and sudden freezing decreased the residual activities of interferons at pH 2 and 9 more than \"normal\" cooling, an effect not observed at pH 7., Score: 0.2332\n",
      "Snippet: The rate of cooling of heated interferon significantly influenced its residual activity., Score: 0.2039\n",
      "Snippet: The degradation of biological activity of virus-induced murine interferon was determined in linear nonisothermal and multiple isothermal tests., Score: 0.2005\n",
      "Snippet: Heat stability was a function of the H+-ion concentration rather than the ionic composition of the buffer; interferon solutions containing monovalent cations with different ionic radii had similar heat stability., Score: 0.1951\n",
      "Snippet: The results showed that (1) poly I : C molecules 0.1-0.3 nm long were the most effective for interferon induction; (2) sonication of poly I : C reduced its molecular length and also the interferon-inducing activity, the degree of reduction varying in different fractions; and (3) the interferon-inducing activity of poly I: C of 0.1-0.3 nm obtained by sucrose density gradient centrifugation was higher than that poly I: C of corresponding length prepared by sonication., Score: 0.1831\n",
      "Snippet: The mixtures of viral fragments exhibited an increased deacetylase activity., Score: 0.1555\n",
      "Snippet: An association between viral hepatitis and two rheumatic disease syndromes has been observed., Score: 0.1546\n"
     ]
    }
   ],
   "source": [
    "file_path = \"/Users/onurcanmemis/Desktop/Lectures/Information_Retrieval/Project/ir-bioasq/main_articles_head1000.csv\"\n",
    "query = \"Effects of interferon on viral infections\"\n",
    "\n",
    "# Instantiate the model\n",
    "model = QuerySpecificTFIDFModelLogarithmic()\n",
    "\n",
    "# Get relevant documents and snippets\n",
    "top_documents, top_snippets = model.get_relevant_documents_and_snippets(query, file_path, top_n_docs=10, top_n_snippets=10)\n",
    "\n",
    "# Display results\n",
    "print(\"Top Documents:\")\n",
    "for doc in top_documents.to_dict('records'):\n",
    "    print(f\"PMID: {doc['pmid']}, Score: {doc['score']:.4f}\")\n",
    "\n",
    "print(\"\\nTop Snippets:\")\n",
    "for snippet in top_snippets:\n",
    "    print(f\"Snippet: {snippet['text']}, Score: {snippet['score']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Raw\n",
    "> nfc\n",
    "* raw term frequency (n)\n",
    "* idf (f)\n",
    "* cosine normalization (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuerySpecificTFIDFModelRaw:\n",
    "    def __init__(self):\n",
    "        # Initialize stop words and lemmatizer\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.dictionary = None\n",
    "        self.tfidf_model = None\n",
    "        self.index = None\n",
    "\n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"\n",
    "        Preprocesses text by tokenizing, removing stopwords, and lemmatizing.\n",
    "        \"\"\"\n",
    "        tokens = word_tokenize(text.lower())  # Tokenize and convert to lowercase\n",
    "        tokens = [word for word in tokens if word.isalnum() and word not in self.stop_words]  # Remove stop words and punctuation\n",
    "        tokens = [self.lemmatizer.lemmatize(word) for word in tokens]  # Apply lemmatization\n",
    "        return tokens\n",
    "\n",
    "    def load_and_preprocess_documents(self, file_path):\n",
    "        \"\"\"\n",
    "        Loads and preprocesses documents from a CSV file.\n",
    "        \"\"\"\n",
    "        print(f\"Loading documents from {file_path}\")\n",
    "        df = pd.read_csv(file_path)\n",
    "        df = df.dropna(subset=[\"pmid\", \"title\", \"abstract\"])  # Drop rows with missing values\n",
    "\n",
    "        # Combine title and abstract, and preprocess\n",
    "        df[\"raw_text\"] = df[\"title\"] + \" \" + df[\"abstract\"]\n",
    "        df[\"tokens\"] = df[\"raw_text\"].apply(self.preprocess_text)\n",
    "        return df\n",
    "\n",
    "    def build_tfidf_model(self, documents):\n",
    "        \"\"\"\n",
    "        Builds the TF-IDF model and similarity index using Gensim.\n",
    "        \"\"\"\n",
    "        print(\"Building TF-IDF model...\")\n",
    "        self.dictionary = Dictionary(documents[\"tokens\"])  # Create a Gensim dictionary\n",
    "        corpus = [self.dictionary.doc2bow(tokens) for tokens in documents[\"tokens\"]]  # Convert to bag-of-words format\n",
    "        self.tfidf_model = TfidfModel(corpus,smartirs='nfc')  # Build the TF-IDF model\n",
    "        self.index = SparseMatrixSimilarity(self.tfidf_model[corpus], num_features=len(self.dictionary))  # Build similarity index\n",
    "        return corpus\n",
    "\n",
    "    def calculate_relevance(self, query, corpus):\n",
    "        \"\"\"\n",
    "        Calculates relevance scores for the query against the corpus.\n",
    "        \"\"\"\n",
    "        print(\"Calculating relevance scores...\")\n",
    "        query_tokens = self.preprocess_text(query)\n",
    "        query_bow = self.dictionary.doc2bow(query_tokens)  # Convert query to bag-of-words\n",
    "        query_tfidf = self.tfidf_model[query_bow]  # Convert query to TF-IDF\n",
    "        similarities = self.index[query_tfidf]  # Compute similarities\n",
    "        return similarities\n",
    "\n",
    "    def rank_snippets(self, query, top_documents, top_n_snippets=10):\n",
    "        \"\"\"\n",
    "        Extracts and ranks snippets globally based on similarity to the query.\n",
    "        \"\"\"\n",
    "        print(\"Ranking snippets globally...\")\n",
    "        snippets = []\n",
    "        query_tokens = self.preprocess_text(query)\n",
    "\n",
    "        for _, doc in top_documents.iterrows():\n",
    "            pmid, text = doc[\"pmid\"], doc[\"raw_text\"]\n",
    "            sentences = sent_tokenize(text)\n",
    "            for sentence in sentences:\n",
    "                sentence_tokens = self.preprocess_text(sentence)\n",
    "                sentence_bow = self.dictionary.doc2bow(sentence_tokens)\n",
    "                sentence_tfidf = self.tfidf_model[sentence_bow]\n",
    "                snippet_score = sum(\n",
    "                    score for term_id, score in sentence_tfidf if term_id in [self.dictionary.token2id.get(token) for token in query_tokens]\n",
    "                )\n",
    "                snippets.append({\n",
    "                    \"text\": sentence,\n",
    "                    \"source\": pmid,\n",
    "                    \"score\": snippet_score,\n",
    "                })\n",
    "\n",
    "        # Sort snippets globally\n",
    "        top_snippets = sorted(snippets, key=lambda x: x[\"score\"], reverse=True)[:top_n_snippets]\n",
    "        return top_snippets\n",
    "\n",
    "    def get_relevant_documents_and_snippets(self, query, file_path, top_n_docs=10, top_n_snippets=10):\n",
    "        \"\"\"\n",
    "        Retrieves the top N relevant documents and globally ranked snippets.\n",
    "        \"\"\"\n",
    "        # Load and preprocess documents\n",
    "        documents = self.load_and_preprocess_documents(file_path)\n",
    "        if len(documents) == 0:\n",
    "            print(\"No valid documents found.\")\n",
    "            return [], []\n",
    "\n",
    "        # Build the TF-IDF model\n",
    "        corpus = self.build_tfidf_model(documents)\n",
    "\n",
    "        # Calculate relevance scores\n",
    "        relevance_scores = self.calculate_relevance(query, corpus)\n",
    "\n",
    "        # Retrieve the indices of the top N documents\n",
    "        print(\"Retrieving top documents...\")\n",
    "        top_indices = np.argsort(relevance_scores)[-top_n_docs:][::-1]  # Get indices of top N scores in descending order\n",
    "\n",
    "        # Create a DataFrame with the top N documents\n",
    "        top_documents = documents.iloc[top_indices].copy()\n",
    "        top_documents[\"score\"] = [relevance_scores[idx] for idx in top_indices]\n",
    "\n",
    "        # Rank snippets globally\n",
    "        top_snippets = self.rank_snippets(query, top_documents, top_n_snippets)\n",
    "\n",
    "        return top_documents, top_snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading documents from /Users/onurcanmemis/Desktop/Lectures/Information_Retrieval/Project/ir-bioasq/main_articles_head1000.csv\n",
      "Building TF-IDF model...\n",
      "Calculating relevance scores...\n",
      "Retrieving top documents...\n",
      "Ranking snippets globally...\n",
      "Top Documents:\n",
      "PMID: 2143, Score: 0.5932\n",
      "PMID: 1126, Score: 0.1220\n",
      "PMID: 1990, Score: 0.0874\n",
      "PMID: 2142, Score: 0.0862\n",
      "PMID: 884, Score: 0.0831\n",
      "PMID: 1628, Score: 0.0769\n",
      "PMID: 1604, Score: 0.0712\n",
      "PMID: 1468, Score: 0.0643\n",
      "PMID: 1847, Score: 0.0633\n",
      "PMID: 1629, Score: 0.0616\n",
      "\n",
      "Top Snippets:\n",
      "Snippet: The stabilizing effect of pH during heating on interferon in solution was greatest at low pH, such that pH 2 greater than pH 5 greater than pH 7 greater than or equal to pH 9; freeze-dried preparations of interferon were also more heat-stable at acid pH than at neutral pH., Score: 0.6735\n",
      "Snippet: It is postulated that the physicochemical alterations in the aqueous environment significantly affecting the stability of interferon operate by producing changes in the size and/or conformation of interferon molecules., Score: 0.6325\n",
      "Snippet: Interferon heated to 80degree C could not be reactivated at 40degree C or 55degree C. Interferon of higher apparent molecular weight was more heat-stable than that with lower apparent molecular weight., Score: 0.5826\n",
      "Snippet: The rate of cooling of heated interferon significantly influenced its residual activity., Score: 0.5165\n",
      "Snippet: The influence of physicochemical factors on the thermal inactivation of murine interferon., Score: 0.4844\n",
      "Snippet: The mixtures of viral fragments exhibited an increased deacetylase activity., Score: 0.4796\n",
      "Snippet: A model is proposed that relates thermal inactivation to different possible molecular states of interferon., Score: 0.4796\n",
      "Snippet: Rapid cooling and sudden freezing decreased the residual activities of interferons at pH 2 and 9 more than \"normal\" cooling, an effect not observed at pH 7., Score: 0.4241\n",
      "Snippet: The development of generalized necrotizing vasculitis in association with hepatitis B antigenemia is the first example in man of a chronic rheumatic disease presumably caused by a viral infection., Score: 0.4139\n",
      "Snippet: The degradation of biological activity of virus-induced murine interferon was determined in linear nonisothermal and multiple isothermal tests., Score: 0.3971\n"
     ]
    }
   ],
   "source": [
    "file_path = \"/Users/onurcanmemis/Desktop/Lectures/Information_Retrieval/Project/ir-bioasq/main_articles_head1000.csv\"\n",
    "query = \"Effects of interferon on viral infections\"\n",
    "\n",
    "# Instantiate the model\n",
    "model = QuerySpecificTFIDFModelRaw()\n",
    "\n",
    "# Get relevant documents and snippets\n",
    "top_documents, top_snippets = model.get_relevant_documents_and_snippets(query, file_path, top_n_docs=10, top_n_snippets=10)\n",
    "\n",
    "# Display results\n",
    "print(\"Top Documents:\")\n",
    "for doc in top_documents.to_dict('records'):\n",
    "    print(f\"PMID: {doc['pmid']}, Score: {doc['score']:.4f}\")\n",
    "\n",
    "print(\"\\nTop Snippets:\")\n",
    "for snippet in top_snippets:\n",
    "    print(f\"Snippet: {snippet['text']}, Score: {snippet['score']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Augmented\n",
    "> afc\n",
    "* augmented (a)\n",
    "* idf (f)\n",
    "* cosine normalization (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuerySpecificTFIDFModelAugmented:\n",
    "    def __init__(self):\n",
    "        # Initialize stop words and lemmatizer\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.dictionary = None\n",
    "        self.tfidf_model = None\n",
    "        self.index = None\n",
    "\n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"\n",
    "        Preprocesses text by tokenizing, removing stopwords, and lemmatizing.\n",
    "        \"\"\"\n",
    "        tokens = word_tokenize(text.lower())  # Tokenize and convert to lowercase\n",
    "        tokens = [word for word in tokens if word.isalnum() and word not in self.stop_words]  # Remove stop words and punctuation\n",
    "        tokens = [self.lemmatizer.lemmatize(word) for word in tokens]  # Apply lemmatization\n",
    "        return tokens\n",
    "\n",
    "    def load_and_preprocess_documents(self, file_path):\n",
    "        \"\"\"\n",
    "        Loads and preprocesses documents from a CSV file.\n",
    "        \"\"\"\n",
    "        print(f\"Loading documents from {file_path}\")\n",
    "        df = pd.read_csv(file_path)\n",
    "        df = df.dropna(subset=[\"pmid\", \"title\", \"abstract\"])  # Drop rows with missing values\n",
    "\n",
    "        # Combine title and abstract, and preprocess\n",
    "        df[\"raw_text\"] = df[\"title\"] + \" \" + df[\"abstract\"]\n",
    "        df[\"tokens\"] = df[\"raw_text\"].apply(self.preprocess_text)\n",
    "        return df\n",
    "\n",
    "    def build_tfidf_model(self, documents):\n",
    "        \"\"\"\n",
    "        Builds the TF-IDF model and similarity index using Gensim.\n",
    "        \"\"\"\n",
    "        print(\"Building TF-IDF model...\")\n",
    "        self.dictionary = Dictionary(documents[\"tokens\"])  # Create a Gensim dictionary\n",
    "        corpus = [self.dictionary.doc2bow(tokens) for tokens in documents[\"tokens\"]]  # Convert to bag-of-words format\n",
    "        self.tfidf_model = TfidfModel(corpus,smartirs='afc')  # Build the TF-IDF model\n",
    "        self.index = SparseMatrixSimilarity(self.tfidf_model[corpus], num_features=len(self.dictionary))  # Build similarity index\n",
    "        return corpus\n",
    "\n",
    "    def calculate_relevance(self, query, corpus):\n",
    "        \"\"\"\n",
    "        Calculates relevance scores for the query against the corpus.\n",
    "        \"\"\"\n",
    "        print(\"Calculating relevance scores...\")\n",
    "        query_tokens = self.preprocess_text(query)\n",
    "        query_bow = self.dictionary.doc2bow(query_tokens)  # Convert query to bag-of-words\n",
    "        query_tfidf = self.tfidf_model[query_bow]  # Convert query to TF-IDF\n",
    "        similarities = self.index[query_tfidf]  # Compute similarities\n",
    "        return similarities\n",
    "\n",
    "    def rank_snippets(self, query, top_documents, top_n_snippets=10):\n",
    "        \"\"\"\n",
    "        Extracts and ranks snippets globally based on similarity to the query.\n",
    "        \"\"\"\n",
    "        print(\"Ranking snippets globally...\")\n",
    "        snippets = []\n",
    "        query_tokens = self.preprocess_text(query)\n",
    "\n",
    "        for _, doc in top_documents.iterrows():\n",
    "            pmid, text = doc[\"pmid\"], doc[\"raw_text\"]\n",
    "            sentences = sent_tokenize(text)\n",
    "            for sentence in sentences:\n",
    "                sentence_tokens = self.preprocess_text(sentence)\n",
    "                sentence_bow = self.dictionary.doc2bow(sentence_tokens)\n",
    "                sentence_tfidf = self.tfidf_model[sentence_bow]\n",
    "                snippet_score = sum(\n",
    "                    score for term_id, score in sentence_tfidf if term_id in [self.dictionary.token2id.get(token) for token in query_tokens]\n",
    "                )\n",
    "                snippets.append({\n",
    "                    \"text\": sentence,\n",
    "                    \"source\": pmid,\n",
    "                    \"score\": snippet_score,\n",
    "                })\n",
    "\n",
    "        # Sort snippets globally\n",
    "        top_snippets = sorted(snippets, key=lambda x: x[\"score\"], reverse=True)[:top_n_snippets]\n",
    "        return top_snippets\n",
    "\n",
    "    def get_relevant_documents_and_snippets(self, query, file_path, top_n_docs=10, top_n_snippets=10):\n",
    "        \"\"\"\n",
    "        Retrieves the top N relevant documents and globally ranked snippets.\n",
    "        \"\"\"\n",
    "        # Load and preprocess documents\n",
    "        documents = self.load_and_preprocess_documents(file_path)\n",
    "        if len(documents) == 0:\n",
    "            print(\"No valid documents found.\")\n",
    "            return [], []\n",
    "\n",
    "        # Build the TF-IDF model\n",
    "        corpus = self.build_tfidf_model(documents)\n",
    "\n",
    "        # Calculate relevance scores\n",
    "        relevance_scores = self.calculate_relevance(query, corpus)\n",
    "\n",
    "        # Retrieve the indices of the top N documents\n",
    "        print(\"Retrieving top documents...\")\n",
    "        top_indices = np.argsort(relevance_scores)[-top_n_docs:][::-1]  # Get indices of top N scores in descending order\n",
    "\n",
    "        # Create a DataFrame with the top N documents\n",
    "        top_documents = documents.iloc[top_indices].copy()\n",
    "        top_documents[\"score\"] = [relevance_scores[idx] for idx in top_indices]\n",
    "\n",
    "        # Rank snippets globally\n",
    "        top_snippets = self.rank_snippets(query, top_documents, top_n_snippets)\n",
    "\n",
    "        return top_documents, top_snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading documents from /Users/onurcanmemis/Desktop/Lectures/Information_Retrieval/Project/ir-bioasq/main_articles_head1000.csv\n",
      "Building TF-IDF model...\n",
      "Calculating relevance scores...\n",
      "Retrieving top documents...\n",
      "Ranking snippets globally...\n",
      "Top Documents:\n",
      "PMID: 2143, Score: 0.2059\n",
      "PMID: 1990, Score: 0.1604\n",
      "PMID: 1628, Score: 0.1348\n",
      "PMID: 2142, Score: 0.1306\n",
      "PMID: 1126, Score: 0.1048\n",
      "PMID: 938, Score: 0.0894\n",
      "PMID: 1685, Score: 0.0771\n",
      "PMID: 1792, Score: 0.0764\n",
      "PMID: 670, Score: 0.0690\n",
      "PMID: 334, Score: 0.0628\n",
      "\n",
      "Top Snippets:\n",
      "Snippet: The stabilizing effect of pH during heating on interferon in solution was greatest at low pH, such that pH 2 greater than pH 5 greater than pH 7 greater than or equal to pH 9; freeze-dried preparations of interferon were also more heat-stable at acid pH than at neutral pH., Score: 0.5516\n",
      "Snippet: The rate of cooling of heated interferon significantly influenced its residual activity., Score: 0.5165\n",
      "Snippet: The viral titer reached a maximum of 10(6.75) TCID50/0.1 ml., Score: 0.4876\n",
      "Snippet: Rapid cooling and sudden freezing decreased the residual activities of interferons at pH 2 and 9 more than \"normal\" cooling, an effect not observed at pH 7., Score: 0.4848\n",
      "Snippet: The influence of physicochemical factors on the thermal inactivation of murine interferon., Score: 0.4844\n",
      "Snippet: A model is proposed that relates thermal inactivation to different possible molecular states of interferon., Score: 0.4796\n",
      "Snippet: It is postulated that the physicochemical alterations in the aqueous environment significantly affecting the stability of interferon operate by producing changes in the size and/or conformation of interferon molecules., Score: 0.4781\n",
      "Snippet: Interferon heated to 80degree C could not be reactivated at 40degree C or 55degree C. Interferon of higher apparent molecular weight was more heat-stable than that with lower apparent molecular weight., Score: 0.4609\n",
      "Snippet: The development of generalized necrotizing vasculitis in association with hepatitis B antigenemia is the first example in man of a chronic rheumatic disease presumably caused by a viral infection., Score: 0.4139\n",
      "Snippet: Heat stability was a function of the H+-ion concentration rather than the ionic composition of the buffer; interferon solutions containing monovalent cations with different ionic radii had similar heat stability., Score: 0.3995\n"
     ]
    }
   ],
   "source": [
    "file_path = \"/Users/onurcanmemis/Desktop/Lectures/Information_Retrieval/Project/ir-bioasq/main_articles_head1000.csv\"\n",
    "query = \"Effects of interferon on viral infections\"\n",
    "\n",
    "# Instantiate the model\n",
    "model = QuerySpecificTFIDFModelAugmented()\n",
    "\n",
    "# Get relevant documents and snippets\n",
    "top_documents, top_snippets = model.get_relevant_documents_and_snippets(query, file_path, top_n_docs=10, top_n_snippets=10)\n",
    "\n",
    "# Display results\n",
    "print(\"Top Documents:\")\n",
    "for doc in top_documents.to_dict('records'):\n",
    "    print(f\"PMID: {doc['pmid']}, Score: {doc['score']:.4f}\")\n",
    "\n",
    "print(\"\\nTop Snippets:\")\n",
    "for snippet in top_snippets:\n",
    "    print(f\"Snippet: {snippet['text']}, Score: {snippet['score']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilistic Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BM25ModelWithPandas:\n",
    "    def __init__(self):\n",
    "        # Initialize stop words and lemmatizer\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"\n",
    "        Preprocesses text by removing stopwords, applying lowercase, and lemmatization.\n",
    "        If for_bm25 is True, returns a list of tokens for BM25. Otherwise, returns a single string.\n",
    "        \"\"\"\n",
    "        tokens = text.lower().split()  # Tokenize and convert to lowercase\n",
    "        tokens = [word for word in tokens if word.isalnum() and word not in self.stop_words]  # Remove stop words and punctuation\n",
    "        tokens = [self.lemmatizer.lemmatize(word) for word in tokens]  # Apply lemmatization only\n",
    "        return tokens \n",
    "\n",
    "    def load_documents(self, file_path):\n",
    "        \"\"\"\n",
    "        Loads CSV data using Pandas and preprocesses the `title` and `abstract` fields.\n",
    "        Assumes the file has columns `pmid`, `title`, and `abstract`.\n",
    "        \"\"\"\n",
    "        print(f\"Loading documents from {file_path}\")\n",
    "        df = pd.read_csv(file_path)\n",
    "        df = df.dropna(subset=['pmid', 'title', 'abstract'])  # Drop rows with missing values\n",
    "\n",
    "        # Combine title and abstract, and preprocess\n",
    "        df['raw_text'] = df['title'] + \" \" + df['abstract']\n",
    "        df['preprocessed_text'] = df['raw_text'].apply(self.preprocess_text)\n",
    "        \n",
    "        return df\n",
    "\n",
    "    def calculate_bm25_scores(self, query_tokens, documents):\n",
    "        \"\"\"\n",
    "        Uses BM25 to calculate relevance scores between the query and all documents.\n",
    "        \"\"\"\n",
    "        bm25 = BM25Okapi(list(documents['preprocessed_text']))\n",
    "        relevance_scores = bm25.get_scores(query_tokens)\n",
    "        return relevance_scores\n",
    "\n",
    "    def get_top_snippets(self, query_tokens, top_documents, top_n=10):\n",
    "        \"\"\"\n",
    "        Extracts and ranks snippets globally from the top documents using BM25.\n",
    "        \"\"\"\n",
    "        snippets = []\n",
    "        \n",
    "        for _, doc in top_documents.iterrows():\n",
    "            pmid, abstract = doc['pmid'], doc['raw_text']\n",
    "            sentences = sent_tokenize(abstract)  # Split the abstract into sentences\n",
    "            \n",
    "            for sentence in sentences:\n",
    "                preprocessed_sentence = self.preprocess_text(sentence)\n",
    "                snippets.append({\"text\": sentence, \"tokens\": preprocessed_sentence, \"source\": pmid})\n",
    "        \n",
    "        # Combine all snippets into a single list for BM25\n",
    "        snippet_texts = [snippet[\"tokens\"] for snippet in snippets]\n",
    "        bm25 = BM25Okapi(snippet_texts)\n",
    "        snippet_scores = bm25.get_scores(query_tokens)\n",
    "        \n",
    "        # Add scores to snippets and sort them globally\n",
    "        for i, snippet in enumerate(snippets):\n",
    "            snippet[\"score\"] = snippet_scores[i]\n",
    "        \n",
    "        top_snippets = sorted(snippets, key=lambda x: x[\"score\"], reverse=True)[:top_n]\n",
    "        return top_snippets\n",
    "\n",
    "    def get_relevant_documents_and_snippets(self, query, file_path, top_n_docs=10, top_n_snippets=10):\n",
    "        \"\"\"\n",
    "        Retrieves top N most relevant documents and globally ranks snippets from them.\n",
    "        \"\"\"\n",
    "        # Load documents\n",
    "        documents = self.load_documents(file_path)\n",
    "\n",
    "        if len(documents) == 0:\n",
    "            print(\"No valid documents found.\")\n",
    "            return [], []\n",
    "\n",
    "        # Preprocess the query\n",
    "        query_tokens = self.preprocess_text(query)\n",
    "\n",
    "        # Calculate BM25 relevance scores\n",
    "        relevance_scores = self.calculate_bm25_scores(query_tokens, documents)\n",
    "        documents['score'] = relevance_scores\n",
    "\n",
    "        # Get top N documents\n",
    "        top_documents = documents.nlargest(top_n_docs, 'score')\n",
    "\n",
    "        # Rank snippets globally from top documents\n",
    "        top_snippets = self.get_top_snippets(query_tokens, top_documents, top_n_snippets)\n",
    "\n",
    "        # Return both top documents and snippets\n",
    "        return top_documents, top_snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading documents from /Users/onurcanmemis/Desktop/Lectures/Information_Retrieval/Project/ir-bioasq/main_articles_head1000.csv\n",
      "\n",
      "Top Documents:\n",
      "PMC ID: 2143, Score: 13.0717\n",
      "PMC ID: 1126, Score: 9.4150\n",
      "PMC ID: 2142, Score: 8.3898\n",
      "PMC ID: 1990, Score: 6.2001\n",
      "PMC ID: 938, Score: 6.1988\n",
      "PMC ID: 884, Score: 5.9103\n",
      "PMC ID: 1468, Score: 5.7332\n",
      "PMC ID: 1628, Score: 5.7323\n",
      "PMC ID: 1792, Score: 5.7181\n",
      "PMC ID: 1629, Score: 5.5253\n",
      "\n",
      "Top Snippets:\n",
      "Source: 2143\n",
      "Snippet: Rapid cooling and sudden freezing decreased the residual activities of interferons at pH 2 and 9 more than \"normal\" cooling, an effect not observed at pH 7.\n",
      "Score: 4.3776\n",
      "\n",
      "Source: 1792\n",
      "Snippet: Effect of environmental pH on adenovirus-associated virus.\n",
      "Score: 4.1220\n",
      "\n",
      "Source: 2143\n",
      "Snippet: The stabilizing effect of pH during heating on interferon in solution was greatest at low pH, such that pH 2 greater than pH 5 greater than pH 7 greater than or equal to pH 9; freeze-dried preparations of interferon were also more heat-stable at acid pH than at neutral pH.\n",
      "Score: 3.9315\n",
      "\n",
      "Source: 884\n",
      "Snippet: Comparative study of virological infections in asthmatic and nonasthmatic children.\n",
      "Score: 3.2311\n",
      "\n",
      "Source: 1792\n",
      "Snippet: Under the acid conditions studied, the adenovirus helper and cell activities were only slightly suppressed, with the greatest effect due to aggregation of the virus particles.\n",
      "Score: 2.6973\n",
      "\n",
      "Source: 2143\n",
      "Snippet: It is postulated that the physicochemical alterations in the aqueous environment significantly affecting the stability of interferon operate by producing changes in the size and/or conformation of interferon molecules.\n",
      "Score: 2.6757\n",
      "\n",
      "Source: 2143\n",
      "Snippet: Interferon heated to 80degree C could not be reactivated at 40degree C or 55degree C. Interferon of higher apparent molecular weight was more heat-stable than that with lower apparent molecular weight.\n",
      "Score: 2.5460\n",
      "\n",
      "Source: 2143\n",
      "Snippet: The rate of cooling of heated interferon significantly influenced its residual activity.\n",
      "Score: 2.4958\n",
      "\n",
      "Source: 1468\n",
      "Snippet: The mixtures of viral fragments exhibited an increased deacetylase activity.\n",
      "Score: 2.4594\n",
      "\n",
      "Source: 1126\n",
      "Snippet: It was assumed, however, that some represented atypical clinical forms of EBV infection and that timing of specimen collection was a factor in explaining the paucity of Downey cells.\n",
      "Score: 2.3946\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_path = \"/Users/onurcanmemis/Desktop/Lectures/Information_Retrieval/Project/ir-bioasq/main_articles_head1000.csv\"\n",
    "\n",
    "# Define the query\n",
    "query = \"Effects of interferon on viral infections\"\n",
    "\n",
    "# Initialize the BM25 model\n",
    "bm25_model = BM25ModelWithPandas()\n",
    "\n",
    "# Retrieve top documents and snippets\n",
    "top_documents, top_snippets = bm25_model.get_relevant_documents_and_snippets(\n",
    "    query=query,\n",
    "    file_path=file_path,\n",
    "    top_n_docs=10,\n",
    "    top_n_snippets=10\n",
    ")\n",
    "\n",
    "# Print the top documents\n",
    "print(\"\\nTop Documents:\")\n",
    "for _, doc in top_documents.iterrows():\n",
    "    print(f\"PMC ID: {doc['pmid']}, Score: {doc['score']:.4f}\")\n",
    "\n",
    "# Print the top snippets\n",
    "print(\"\\nTop Snippets:\")\n",
    "for snippet in top_snippets:\n",
    "    print(f\"Source: {snippet['source']}\")\n",
    "    print(f\"Snippet: {snippet['text']}\")\n",
    "    print(f\"Score: {snippet['score']:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BM25S- BM25 with Sparse Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BM25SDocumentRetriever:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initializes the BM25SnippetRetriever with the dataset file path.\n",
    "        \"\"\"\n",
    "        self.df = None\n",
    "        self.retriever = None\n",
    "        self.corpus_tokens = None\n",
    "\n",
    "    def load_data(self,file_path):\n",
    "        \"\"\"\n",
    "        Loads the dataset and preprocesses the text.\n",
    "        \"\"\"\n",
    "        print(\"Loading dataset...\")\n",
    "        self.df = pd.read_csv(file_path)\n",
    "        self.df[\"text\"] = self.df[\"title\"] + \" \" + self.df[\"abstract\"]\n",
    "        self.corpus_tokens = tokenize(self.df[\"text\"].tolist())\n",
    "\n",
    "    def build_corpus_index(self):\n",
    "        \"\"\"\n",
    "        Initializes the BM25 retriever and indexes the tokenized corpus.\n",
    "        \"\"\"\n",
    "        print(\"Building corpus index...\")\n",
    "        self.retriever = BM25()\n",
    "        self.retriever.index(self.corpus_tokens)\n",
    "\n",
    "    def retrieve_top_documents(self, query, k=10):\n",
    "        \"\"\"\n",
    "        Retrieves the top-k most relevant documents for the given query.\n",
    "        \"\"\"\n",
    "        print(\"Retrieving top documents...\")\n",
    "        query_tokens = tokenize(query)\n",
    "        docs, scores = self.retriever.retrieve(query_tokens, k=k)\n",
    "\n",
    "        # Map document indices back to the dataset\n",
    "        top_docs_indices = docs[0]\n",
    "        top_docs_scores = scores[0]\n",
    "\n",
    "        # Extract the top documents with their scores\n",
    "        top_documents = [\n",
    "            {\"text\": self.df.iloc[idx][\"text\"], \"score\": score, \"pmid\": self.df.iloc[idx][\"pmid\"]}\n",
    "            for idx, score in zip(top_docs_indices, top_docs_scores)\n",
    "        ]\n",
    "        return top_documents\n",
    "\n",
    "    def retrieve_top_snippets(self, query, top_documents, k=10):\n",
    "        \"\"\"\n",
    "        Retrieves the top-k most relevant snippets globally from the given top documents.\n",
    "        \"\"\"\n",
    "        print(\"Retrieving top snippets...\")\n",
    "        query_tokens = tokenize(query)\n",
    "\n",
    "        # Consolidate all snippets with document IDs\n",
    "        all_snippets = []\n",
    "        for doc in top_documents:\n",
    "            sentences = sent_tokenize(doc[\"text\"])  # Split the document into sentences (snippets)\n",
    "            for sentence in sentences:\n",
    "                all_snippets.append({\"text\": sentence, \"source\": doc[\"pmid\"]})\n",
    "\n",
    "        # Tokenize all snippets\n",
    "        snippet_tokens = tokenize([snippet[\"text\"] for snippet in all_snippets])\n",
    "\n",
    "        # Re-index the BM25 retriever with snippets\n",
    "        self.retriever.index(snippet_tokens)\n",
    "\n",
    "        # Retrieve the top k most relevant snippets globally\n",
    "        snippet_docs, snippet_scores = self.retriever.retrieve(query_tokens, k=k)\n",
    "\n",
    "        # Extract the top k snippets with scores and source document IDs\n",
    "        top_snippets = [\n",
    "            {\n",
    "                \"text\": all_snippets[idx][\"text\"],\n",
    "                \"score\": snippet_scores[0, i],\n",
    "                \"source\": all_snippets[idx][\"source\"],\n",
    "            }\n",
    "            for i, idx in enumerate(snippet_docs[0])\n",
    "        ]\n",
    "        return top_snippets\n",
    "\n",
    "    def get_relevant_documents_and_snippets(self, query,file_path, top_n_docs=10, top_n_snippets=10):\n",
    "        \"\"\"\n",
    "        Main method to retrieve top documents and top snippets for a given query.\n",
    "        \"\"\"\n",
    "        # Load the dataset and build the index\n",
    "        self.load_data(file_path)\n",
    "        self.build_corpus_index()\n",
    "\n",
    "        # Retrieve top documents\n",
    "        top_documents = self.retrieve_top_documents(query, k=top_n_docs)\n",
    "\n",
    "        # Print top documents\n",
    "        print(\"\\nTop 10 Documents:\")\n",
    "        for doc in top_documents:\n",
    "            print(f\"PMC ID: {doc['pmid']}, Score: {doc['score']:.2f}\")\n",
    "            print(f\"Text: {doc['text'][:200]}...\")  # Print a snippet of the document text\n",
    "            print(\"-\" * 80)\n",
    "\n",
    "        # Retrieve top snippets\n",
    "        top_snippets = self.retrieve_top_snippets(query, top_documents, k=top_n_snippets)\n",
    "\n",
    "        # Print top snippets\n",
    "        print(\"\\nTop 10 Snippets:\")\n",
    "        for snippet in top_snippets:\n",
    "            print(f\"Source Document: {snippet['source']}\")\n",
    "            print(f\"Snippet: {snippet['text']}\")\n",
    "            print(f\"Score: {snippet['score']:.2f}\")\n",
    "            print(\"-\" * 80)\n",
    "\n",
    "        return top_documents, top_snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building corpus index...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving top documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 Documents:\n",
      "PMC ID: 2143, Score: 5.13\n",
      "Text: The influence of physicochemical factors on the thermal inactivation of murine interferon. The degradation of biological activity of virus-induced murine interferon was determined in linear nonisother...\n",
      "--------------------------------------------------------------------------------\n",
      "PMC ID: 1990, Score: 4.91\n",
      "Text: Correlation between molecular size and interferon- inducing activity of poly I:C. Electron microscopy showed that commerical poly I: C consisted of molecules varying in length from less than 0.05 nm t...\n",
      "--------------------------------------------------------------------------------\n",
      "PMC ID: 1126, Score: 3.54\n",
      "Text: The specificity of heterophil antibodies in patients and healthy donors with no or minimal signs of infectious mononucleosis. Over several years sera were collected from 14 heterophil-positive student...\n",
      "--------------------------------------------------------------------------------\n",
      "PMC ID: 1604, Score: 2.76\n",
      "Text: The significance of mosquito longevity and blood-feeding behaviour in the dynamics of arbovirus infections. Mosquito longevity and blood-feeding behaviour are very important but neglected factors in t...\n",
      "--------------------------------------------------------------------------------\n",
      "PMC ID: 331, Score: 2.65\n",
      "Text: Effect of pneumococci on blood clotting, platelets, and polymorphonuclear leukocytes. Infections due to Streptococcus pneumoniae and products from the organism have been associated with alterations in...\n",
      "--------------------------------------------------------------------------------\n",
      "PMC ID: 938, Score: 2.50\n",
      "Text: The virus hypothesis in systemic lupus erythematosus. Type-C viruses are currently the prime etiologic candidates in systemic lupus erythematosus. On the basis of knowledge gained from studies of expe...\n",
      "--------------------------------------------------------------------------------\n",
      "PMC ID: 1629, Score: 2.40\n",
      "Text: Polyarthritis, polyarteritis and hepatitis B. An association between viral hepatitis and two rheumatic disease syndromes has been observed. Twenty-nine patients manifested a transient polyarthritis, s...\n",
      "--------------------------------------------------------------------------------\n",
      "PMC ID: 1628, Score: 2.40\n",
      "Text: Vasculitis with hepatitis B antigenemia: long-term observation in nine patients. The development of generalized necrotizing vasculitis in association with hepatitis B antigenemia is the first example ...\n",
      "--------------------------------------------------------------------------------\n",
      "PMC ID: 884, Score: 2.34\n",
      "Text: Comparative study of virological infections in asthmatic and nonasthmatic children. The author shows complex analyses: clinical, laboratory, X-rays, bronchoscopical, bronchographical and measuring lun...\n",
      "--------------------------------------------------------------------------------\n",
      "PMC ID: 1468, Score: 2.19\n",
      "Text: Disruption of Vi bacteriophage III and localization of its deacetylase activity. It has been shown that particles of Vi bacteriophage III catalyse deacetylation of O-acetyl pectic (polygalacturonic) a...\n",
      "--------------------------------------------------------------------------------\n",
      "Retrieving top snippets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 Snippets:\n",
      "Source Document: 884\n",
      "Snippet: Comparative study of virological infections in asthmatic and nonasthmatic children.\n",
      "Score: 1.39\n",
      "--------------------------------------------------------------------------------\n",
      "Source Document: 331\n",
      "Snippet: Thus, pneumococci exert several dose-dependent thromboplastic effects: (i) release of platelet thromboplastic substances; (ii) a direct thromboplastic effect; and (iii) release of polymorphonuclear coagulant.\n",
      "Score: 1.36\n",
      "--------------------------------------------------------------------------------\n",
      "Source Document: 1604\n",
      "Snippet: The significance of mosquito longevity and blood-feeding behaviour in the dynamics of arbovirus infections.\n",
      "Score: 1.29\n",
      "--------------------------------------------------------------------------------\n",
      "Source Document: 1468\n",
      "Snippet: The mixtures of viral fragments exhibited an increased deacetylase activity.\n",
      "Score: 1.23\n",
      "--------------------------------------------------------------------------------\n",
      "Source Document: 1468\n",
      "Snippet: Amongst the viral components, these structures showed the highest specific deacetylase activity.\n",
      "Score: 1.14\n",
      "--------------------------------------------------------------------------------\n",
      "Source Document: 1629\n",
      "Snippet: An association between viral hepatitis and two rheumatic disease syndromes has been observed.\n",
      "Score: 1.06\n",
      "--------------------------------------------------------------------------------\n",
      "Source Document: 331\n",
      "Snippet: Infections due to Streptococcus pneumoniae and products from the organism have been associated with alterations in blood clotting and function of platelets.\n",
      "Score: 1.06\n",
      "--------------------------------------------------------------------------------\n",
      "Source Document: 2143\n",
      "Snippet: It is postulated that the physicochemical alterations in the aqueous environment significantly affecting the stability of interferon operate by producing changes in the size and/or conformation of interferon molecules.\n",
      "Score: 1.02\n",
      "--------------------------------------------------------------------------------\n",
      "Source Document: 1604\n",
      "Snippet: Mosquito longevity and blood-feeding behaviour are very important but neglected factors in the dynamics of arbovirus infections as changes in them affect transmission rates exponentially.\n",
      "Score: 0.97\n",
      "--------------------------------------------------------------------------------\n",
      "Source Document: 2143\n",
      "Snippet: The influence of physicochemical factors on the thermal inactivation of murine interferon.\n",
      "Score: 0.96\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "file_path = \"/Users/onurcanmemis/Desktop/Lectures/Information_Retrieval/Project/ir-bioasq/main_articles_head1000.csv\"\n",
    "query = \"Effects of interferon on viral infections\"\n",
    "\n",
    "bm25_model = BM25SDocumentRetriever()\n",
    "top_documents, top_snippets = bm25_model.get_relevant_documents_and_snippets(query=query,file_path=file_path, top_n_docs=10, top_n_snippets=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic Retrieval Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic IR Model- With Speed Ups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SemanticRetrievalModelWithPandasOptimized:\n",
    "    def __init__(self, model_name='sentence-transformers/paraphrase-MiniLM-L3-v2', use_gpu=True):\n",
    "        \"\"\"\n",
    "        Initialize the semantic model using a pre-trained Sentence-BERT model.\n",
    "        \"\"\"\n",
    "        device = \"cuda\" if use_gpu and torch.cuda.is_available() else \"cpu\"\n",
    "        self.embedding_model = SentenceTransformer(model_name, device=device)\n",
    "\n",
    "    def preprocess_documents(self, file_path):\n",
    "        \"\"\"\n",
    "        Loads and preprocesses documents using Pandas. Assumes the CSV file has columns `pmid`, `title`, and `abstract`.\n",
    "        \"\"\"\n",
    "        print(f\"Loading documents from {file_path}\")\n",
    "        df = pd.read_csv(file_path)\n",
    "        df.dropna(subset=['pmid', 'title', 'abstract'], inplace=True)  # Drop rows with missing values\n",
    "\n",
    "        # Combine title and abstract into a single text column\n",
    "        df['text'] = df['title'] + \" \" + df['abstract']\n",
    "        return df\n",
    "\n",
    "    def encode_batch_text(self, texts):\n",
    "        \"\"\"\n",
    "        Encodes a batch of texts into embeddings using the Sentence-BERT model.\n",
    "        \"\"\"\n",
    "        embeddings = self.embedding_model.encode(texts, convert_to_tensor=True, batch_size=32)\n",
    "        return embeddings.cpu()  # Ensure embeddings are moved to CPU\n",
    "\n",
    "    def build_faiss_index(self, embeddings):\n",
    "        \"\"\"\n",
    "        Builds a FAISS index for approximate nearest neighbor search.\n",
    "        \"\"\"\n",
    "        embeddings_np = np.array(embeddings)  # Convert embeddings to NumPy array\n",
    "        d = embeddings_np.shape[1]  # Dimension of embeddings\n",
    "        index = faiss.IndexFlatL2(d)\n",
    "        index.add(embeddings_np)  # Add embeddings to the index\n",
    "        return index\n",
    "\n",
    "    def search_faiss_index(self, index, query_embedding, top_k=10):\n",
    "        \"\"\"\n",
    "        Searches the FAISS index for the top-k most similar embeddings.\n",
    "        \"\"\"\n",
    "        query_embedding_np = query_embedding.cpu().numpy().reshape(1, -1)  # Move query embedding to CPU\n",
    "        distances, indices = index.search(query_embedding_np, top_k)\n",
    "        return distances[0], indices[0]\n",
    "\n",
    "    def filter_documents(self, query, documents, embeddings, top_n_docs=10):\n",
    "        \"\"\"\n",
    "        Filters documents using approximate semantic similarity.\n",
    "        \"\"\"\n",
    "        query_embedding = self.encode_batch_text([query])\n",
    "        index = self.build_faiss_index(embeddings)\n",
    "        distances, indices = self.search_faiss_index(index, query_embedding, top_n_docs)\n",
    "        \n",
    "        top_documents = [\n",
    "            {\n",
    "                \"pmc_id\": documents.iloc[i][\"pmid\"],\n",
    "                \"text\": documents.iloc[i][\"text\"],\n",
    "                \"score\": 1 / (1 + distances[idx]),  # Inverse scaling to normalize distance\n",
    "                \"url\": f\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC{documents.iloc[i]['pmid']}/\",\n",
    "            }\n",
    "            for idx, i in enumerate(indices)\n",
    "        ]\n",
    "        return top_documents, query_embedding\n",
    "\n",
    "    def rank_snippets(self, query_embedding, top_documents, top_n_snippets=10):\n",
    "        \"\"\"\n",
    "        Ranks snippets globally based on semantic similarity.\n",
    "        \"\"\"\n",
    "        snippets = []\n",
    "        for doc in top_documents:\n",
    "            sentences = sent_tokenize(doc[\"text\"])  # Split the document into sentences\n",
    "            snippet_embeddings = self.encode_batch_text(sentences)\n",
    "            snippet_scores = cosine_similarity(query_embedding.cpu().numpy(), snippet_embeddings.cpu().numpy())[0]\n",
    "            \n",
    "            for i, sentence in enumerate(sentences):\n",
    "                snippets.append({\n",
    "                    \"text\": sentence,\n",
    "                    \"source\": doc[\"pmc_id\"],\n",
    "                    \"score\": snippet_scores[i],\n",
    "                })\n",
    "\n",
    "        # Sort snippets globally by score\n",
    "        top_snippets = sorted(snippets, key=lambda x: x[\"score\"], reverse=True)[:top_n_snippets]\n",
    "        return top_snippets\n",
    "\n",
    "    def get_relevant_documents_and_snippets(self, query, file_path, top_n_docs=10, top_n_snippets=10):\n",
    "        \"\"\"\n",
    "        Retrieves top N most relevant documents and globally ranks snippets from them.\n",
    "        \"\"\"\n",
    "        # Load documents with Pandas\n",
    "        df = self.preprocess_documents(file_path)\n",
    "\n",
    "        if len(df) == 0:\n",
    "            print(\"No valid documents found.\")\n",
    "            return [], []\n",
    "\n",
    "        # Encode document embeddings in batches\n",
    "        print(\"Encoding document embeddings...\")\n",
    "        embeddings = np.array([embedding.cpu().numpy() for embedding in self.encode_batch_text(df['text'].tolist())])\n",
    "\n",
    "        # Filter top documents using semantic similarity\n",
    "        print(\"Filtering top documents...\")\n",
    "        top_documents, query_embedding = self.filter_documents(query, df, embeddings, top_n_docs=top_n_docs)\n",
    "\n",
    "        # Rank snippets globally\n",
    "        print(\"Ranking snippets globally...\")\n",
    "        top_snippets = self.rank_snippets(query_embedding, top_documents, top_n_snippets=top_n_snippets)\n",
    "\n",
    "        return top_documents, top_snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading documents from /Users/onurcanmemis/Desktop/Lectures/Information_Retrieval/Project/ir-bioasq/main_articles_head1000.csv\n",
      "Encoding document embeddings...\n",
      "Filtering top documents...\n",
      "Ranking snippets globally...\n",
      "\n",
      "Top 10 Documents:\n",
      "PMC ID: 1295, URL: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1295/, Score: 0.0398\n",
      "PMC ID: 2143, URL: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2143/, Score: 0.0397\n",
      "PMC ID: 1628, URL: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1628/, Score: 0.0389\n",
      "PMC ID: 1990, URL: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1990/, Score: 0.0379\n",
      "PMC ID: 1996, URL: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1996/, Score: 0.0379\n",
      "PMC ID: 725, URL: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC725/, Score: 0.0373\n",
      "PMC ID: 1801, URL: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1801/, Score: 0.0371\n",
      "PMC ID: 2396, URL: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2396/, Score: 0.0371\n",
      "PMC ID: 1296, URL: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1296/, Score: 0.0364\n",
      "PMC ID: 1145, URL: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1145/, Score: 0.0364\n",
      "\n",
      "Top 10 Snippets:\n",
      "Source: https://www.ncbi.nlm.nih.gov/pmc/articles/2143/\n",
      "Snippet: It is postulated that the physicochemical alterations in the aqueous environment significantly affecting the stability of interferon operate by producing changes in the size and/or conformation of interferon molecules.\n",
      "Score: 0.4390\n",
      "\n",
      "Source: https://www.ncbi.nlm.nih.gov/pmc/articles/2143/\n",
      "Snippet: Interferon heated to 80degree C could not be reactivated at 40degree C or 55degree C. Interferon of higher apparent molecular weight was more heat-stable than that with lower apparent molecular weight.\n",
      "Score: 0.4115\n",
      "\n",
      "Source: https://www.ncbi.nlm.nih.gov/pmc/articles/1295/\n",
      "Snippet: Prolonged survival of weakly incompatible skin allografts in mice (across the barrier presented by the MSA) can be induced by pretreating the recipients not only with a specific anti-MSA serum (obtained on day 5 after a single MSA-incompatible skin graft) but also be means of control serum obtained in a similar way from the recipients of fully compatible (syngeneic) skin grafts.\n",
      "Score: 0.4006\n",
      "\n",
      "Source: https://www.ncbi.nlm.nih.gov/pmc/articles/2143/\n",
      "Snippet: The rate of cooling of heated interferon significantly influenced its residual activity.\n",
      "Score: 0.3959\n",
      "\n",
      "Source: https://www.ncbi.nlm.nih.gov/pmc/articles/2143/\n",
      "Snippet: A model is proposed that relates thermal inactivation to different possible molecular states of interferon.\n",
      "Score: 0.3583\n",
      "\n",
      "Source: https://www.ncbi.nlm.nih.gov/pmc/articles/1628/\n",
      "Snippet: Vasculitis with hepatitis B antigenemia: long-term observation in nine patients.\n",
      "Score: 0.3560\n",
      "\n",
      "Source: https://www.ncbi.nlm.nih.gov/pmc/articles/1628/\n",
      "Snippet: The natural history of the disease is emphasized and the manifestations of patients with vasculitis who carry hepatitis B antigen are compared with those of vasculitis patients who are antigen negative.\n",
      "Score: 0.3497\n",
      "\n",
      "Source: https://www.ncbi.nlm.nih.gov/pmc/articles/2396/\n",
      "Snippet: A solid-phase system was set up, using antisera to cortisol-21-BSA conjucates coupled to CNBr-activated cellulose.\n",
      "Score: 0.3390\n",
      "\n",
      "Source: https://www.ncbi.nlm.nih.gov/pmc/articles/2143/\n",
      "Snippet: The stabilizing effect of pH during heating on interferon in solution was greatest at low pH, such that pH 2 greater than pH 5 greater than pH 7 greater than or equal to pH 9; freeze-dried preparations of interferon were also more heat-stable at acid pH than at neutral pH.\n",
      "Score: 0.3344\n",
      "\n",
      "Source: https://www.ncbi.nlm.nih.gov/pmc/articles/1628/\n",
      "Snippet: This report reviews the experience in nine biopsy-proven cases of hepatitis B-associated necrotizing vasculitis followed for up to six years.\n",
      "Score: 0.3193\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "model = SemanticRetrievalModelWithPandasOptimized()\n",
    "\n",
    "# Define the query and CSV file path\n",
    "query = \"Multiple sclerosis treatments using interferon\"\n",
    "file_path = \"/Users/onurcanmemis/Desktop/Lectures/Information_Retrieval/Project/ir-bioasq/main_articles_head1000.csv\"\n",
    "\n",
    "# Retrieve top documents and snippets\n",
    "top_documents, top_snippets = model.get_relevant_documents_and_snippets(\n",
    "    query=query,\n",
    "    file_path=file_path,\n",
    "    top_n_docs=10,\n",
    "    top_n_snippets=10\n",
    ")\n",
    "\n",
    "# Print the top 10 documents\n",
    "print(\"\\nTop 10 Documents:\")\n",
    "for doc in top_documents:\n",
    "    print(f\"PMC ID: {doc['pmc_id']}, URL: {doc['url']}, Score: {doc['score']:.4f}\")\n",
    "\n",
    "# Print the top 10 snippets\n",
    "print(\"\\nTop 10 Snippets:\")\n",
    "for snippet in top_snippets:\n",
    "    print(f\"Source: https://www.ncbi.nlm.nih.gov/pmc/articles/{snippet['source']}/\")\n",
    "    print(f\"Snippet: {snippet['text']}\")\n",
    "    print(f\"Score: {snippet['score']:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Commplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating QuerySpecificTFIDFModelLogarithmic...\n",
      "Loading documents from /Users/onurcanmemis/Desktop/Lectures/Information_Retrieval/Project/ir-bioasq/main_articles_head1000.csv\n",
      "Building TF-IDF model...\n",
      "Calculating relevance scores...\n",
      "Retrieving top documents...\n",
      "Ranking snippets globally...\n",
      "Evaluating QuerySpecificTFIDFModelRaw...\n",
      "Loading documents from /Users/onurcanmemis/Desktop/Lectures/Information_Retrieval/Project/ir-bioasq/main_articles_head1000.csv\n",
      "Building TF-IDF model...\n",
      "Calculating relevance scores...\n",
      "Retrieving top documents...\n",
      "Ranking snippets globally...\n",
      "Evaluating QuerySpecificTFIDFModelAugmented...\n",
      "Loading documents from /Users/onurcanmemis/Desktop/Lectures/Information_Retrieval/Project/ir-bioasq/main_articles_head1000.csv\n",
      "Building TF-IDF model...\n",
      "Calculating relevance scores...\n",
      "Retrieving top documents...\n",
      "Ranking snippets globally...\n",
      "Evaluating BM25ModelWithPandas...\n",
      "Loading documents from /Users/onurcanmemis/Desktop/Lectures/Information_Retrieval/Project/ir-bioasq/main_articles_head1000.csv\n",
      "Evaluating SemanticRetrievalModelWithPandasOptimized...\n",
      "Loading documents from /Users/onurcanmemis/Desktop/Lectures/Information_Retrieval/Project/ir-bioasq/main_articles_head1000.csv\n",
      "Encoding document embeddings...\n",
      "Filtering top documents...\n",
      "Ranking snippets globally...\n",
      "Evaluating BM25SparseMatrixVersion...\n",
      "Loading dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building corpus index...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving top documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 Documents:\n",
      "PMC ID: 2143, Score: 6.41\n",
      "Text: The influence of physicochemical factors on the thermal inactivation of murine interferon. The degradation of biological activity of virus-induced murine interferon was determined in linear nonisother...\n",
      "--------------------------------------------------------------------------------\n",
      "PMC ID: 1990, Score: 4.91\n",
      "Text: Correlation between molecular size and interferon- inducing activity of poly I:C. Electron microscopy showed that commerical poly I: C consisted of molecules varying in length from less than 0.05 nm t...\n",
      "--------------------------------------------------------------------------------\n",
      "PMC ID: 537, Score: 2.77\n",
      "Text: Multiple cyclic nucleotide phosphodiesterases in rat kidney. Using DEAE-cellulose chromatography and Agarose gel filtration we have partially purified a low Km cyclic adenosine monophosphate (AMP) pho...\n",
      "--------------------------------------------------------------------------------\n",
      "PMC ID: 159, Score: 2.60\n",
      "Text: Serum lactate dehydrogenase activity ratios with different substrates. 1. The lactate dehydrogenase activity of 89 sera from patients suffering myocardial infarction and of 55 sera from patients with ...\n",
      "--------------------------------------------------------------------------------\n",
      "PMC ID: 377, Score: 2.45\n",
      "Text: Studies on cathepsins of rat liver lysosomes. II. Comparative studies on multiple forms of cathepsin A. The multiple forms of cathepsin A (AI, AII, and AIII) purified from the lysosome fraction of rat...\n",
      "--------------------------------------------------------------------------------\n",
      "PMC ID: 451, Score: 2.33\n",
      "Text: Hemoglobins and hemocyanins: comparative aspects of structure and function. Comparative studies of protein structure and function can be quite interesting by themselves, and even more interesting when...\n",
      "--------------------------------------------------------------------------------\n",
      "PMC ID: 1268, Score: 2.23\n",
      "Text: Polyadenylated RNA from Vicia faba meristematic root cells. Localization and size estimation of the poly (A) segment. After incubating root apices from two-day-old bean seedlings with [3H] adenine the...\n",
      "--------------------------------------------------------------------------------\n",
      "PMC ID: 907, Score: 2.17\n",
      "Text: Congenital malformations of the central nervous system produced by narcotic analgesics in the hamster. Maternal dose--fetal teratogenic response data were obtained for a variety of narcotic and relate...\n",
      "--------------------------------------------------------------------------------\n",
      "PMC ID: 1459, Score: 2.14\n",
      "Text: Water regulation by a presumptive hormone contained in identified neurosecretory cell R15 of Aplysia. Injection of an homogenate of identified neuron R15 into the hemocele of Aplysia produced a weight...\n",
      "--------------------------------------------------------------------------------\n",
      "PMC ID: 412, Score: 2.11\n",
      "Text: Stimulation of lactic acid production in chick embryo fibroblasts by serum and high pH in the absence of external glucose. Lactic acid production by chick embryo fibroblasts occurs in the absence of e...\n",
      "--------------------------------------------------------------------------------\n",
      "Retrieving top snippets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 Snippets:\n",
      "Source Document: 2143\n",
      "Snippet: The degradation of biological activity of virus-induced murine interferon was determined in linear nonisothermal and multiple isothermal tests.\n",
      "Score: 1.69\n",
      "--------------------------------------------------------------------------------\n",
      "Source Document: 1268\n",
      "Snippet: The alterations of the RNA molecules due to the various treatments were monitored by sucrose density gradients.\n",
      "Score: 1.44\n",
      "--------------------------------------------------------------------------------\n",
      "Source Document: 451\n",
      "Snippet: Our studies suggest the possibility of using Limulus hemocyanin and other hemocyanins as structural homologs and analogs of more complex macromolecular arrays.\n",
      "Score: 1.23\n",
      "--------------------------------------------------------------------------------\n",
      "Source Document: 377\n",
      "Snippet: Comparative studies on multiple forms of cathepsin A.\n",
      "Score: 1.18\n",
      "--------------------------------------------------------------------------------\n",
      "Source Document: 1459\n",
      "Snippet: The results of bioassays of R15 extracts subjected to different treatments are consistent with the hypothesis that activity is due to one or more stable polypeptides of relatively low molecular weight.\n",
      "Score: 1.13\n",
      "--------------------------------------------------------------------------------\n",
      "Source Document: 537\n",
      "Snippet: Multiple cyclic nucleotide phosphodiesterases in rat kidney.\n",
      "Score: 1.13\n",
      "--------------------------------------------------------------------------------\n",
      "Source Document: 412\n",
      "Snippet: The results suggest that treatments which stimulate cell multiplication also activate those enzymatic pathways which convert amino acids to pyruvic and thence to lactic acid.\n",
      "Score: 1.11\n",
      "--------------------------------------------------------------------------------\n",
      "Source Document: 2143\n",
      "Snippet: It is postulated that the physicochemical alterations in the aqueous environment significantly affecting the stability of interferon operate by producing changes in the size and/or conformation of interferon molecules.\n",
      "Score: 1.06\n",
      "--------------------------------------------------------------------------------\n",
      "Source Document: 537\n",
      "Snippet: Using DEAE-cellulose chromatography and Agarose gel filtration we have partially purified a low Km cyclic adenosine monophosphate (AMP) phosphodiesterase from the 100,000 X g supernatant of rat kidneys.\n",
      "Score: 1.00\n",
      "--------------------------------------------------------------------------------\n",
      "Source Document: 2143\n",
      "Snippet: The influence of physicochemical factors on the thermal inactivation of murine interferon.\n",
      "Score: 0.99\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Comparison Results:\n",
      "Model: QuerySpecificTFIDFModelLogarithmic, Time Taken: 0.52 seconds\n",
      "Model: QuerySpecificTFIDFModelRaw, Time Taken: 1.38 seconds\n",
      "Model: QuerySpecificTFIDFModelAugmented, Time Taken: 1.36 seconds\n",
      "Model: BM25ModelWithPandas, Time Taken: 0.34 seconds\n",
      "Model: SemanticRetrievalModelWithPandasOptimized, Time Taken: 7.94 seconds\n",
      "Model: BM25SparseMatrixVersion, Time Taken: 0.22 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Path to the CSV file\n",
    "csv_file_path = \"/Users/onurcanmemis/Desktop/Lectures/Information_Retrieval/Project/ir-bioasq/main_articles_head1000.csv\"\n",
    "\n",
    "# Query to use for comparison\n",
    "query = \"Multiple sclerosis treatments using interferon\"\n",
    "\n",
    "# Number of documents and snippets to retrieve\n",
    "top_n_docs = 10\n",
    "top_n_snippets = 10\n",
    "\n",
    "# List of models to compare\n",
    "models = [\n",
    "    {\n",
    "        \"name\": \"QuerySpecificTFIDFModelLogarithmic\",\n",
    "        \"class\": QuerySpecificTFIDFModelLogarithmic,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"QuerySpecificTFIDFModelRaw\",\n",
    "        \"class\": QuerySpecificTFIDFModelRaw,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"QuerySpecificTFIDFModelAugmented\",\n",
    "        \"class\": QuerySpecificTFIDFModelAugmented,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"BM25ModelWithPandas\",\n",
    "        \"class\": BM25ModelWithPandas,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"SemanticRetrievalModelWithPandasOptimized\",\n",
    "        \"class\": SemanticRetrievalModelWithPandasOptimized,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"BM25SparseMatrixVersion\",\n",
    "        \"class\": BM25SDocumentRetriever,\n",
    "    },\n",
    "]\n",
    "\n",
    "# Function to measure execution time of a model\n",
    "def measure_execution_time(model_class, csv_file_path, query, top_n_docs, top_n_snippets):\n",
    "    model = model_class()  # Instantiate the model\n",
    "    start_time = time.time()\n",
    "    model.get_relevant_documents_and_snippets(\n",
    "        query, csv_file_path, top_n_docs=top_n_docs, top_n_snippets=top_n_snippets\n",
    "    )\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    return elapsed_time\n",
    "\n",
    "# Compare the models\n",
    "results = []\n",
    "for model_info in models:\n",
    "    model_name = model_info[\"name\"]\n",
    "    model_class = model_info[\"class\"]\n",
    "    print(f\"Evaluating {model_name}...\")\n",
    "    elapsed_time = measure_execution_time(\n",
    "        model_class, csv_file_path, query, top_n_docs, top_n_snippets\n",
    "    )\n",
    "    results.append({\"Model\": model_name, \"Time (seconds)\": elapsed_time})\n",
    "\n",
    "# Print results\n",
    "print(\"\\nComparison Results:\")\n",
    "for result in results:\n",
    "    print(f\"Model: {result['Model']}, Time Taken: {result['Time (seconds)']:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VSM Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VSM- TF-IDF method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/onurcanmemis/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/onurcanmemis/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/onurcanmemis/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import nltk\n",
    "\n",
    "# Download NLTK resources for stop-words and sentence tokenization\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "\n",
    "\n",
    "class QuerySpecificTFIDFModel:\n",
    "    def __init__(self):\n",
    "        # Initialize stop words and lemmatizer\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.vectorizer = TfidfVectorizer(\n",
    "            stop_words='english', smooth_idf=True, sublinear_tf=True,\n",
    "            max_df=0.8, min_df=2  # Ignore overly common/rare terms\n",
    "        )\n",
    "    \n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"\n",
    "        Preprocesses text by lowercasing, removing stop words, and lemmatizing.\n",
    "        \"\"\"\n",
    "        tokens = text.lower().split()\n",
    "        tokens = [word for word in tokens if word.isalnum() and word not in self.stop_words]\n",
    "        tokens = [self.lemmatizer.lemmatize(word) for word in tokens]\n",
    "        return ' '.join(tokens)\n",
    "\n",
    "    def load_csv_data(self, file_path):\n",
    "        \"\"\"\n",
    "        Loads CSV data using Dask and extracts the necessary fields (pmid, title, abstract).\n",
    "        Returns a Dask DataFrame for further processing.\n",
    "        \"\"\"\n",
    "        print(f\"Loading CSV file: {file_path}\")\n",
    "        data = dd.read_csv(file_path)\n",
    "\n",
    "        # Filter rows with missing values in critical columns\n",
    "        data = data.dropna(subset=[\"pmid\", \"title\", \"abstract\"])\n",
    "\n",
    "        # Combine title and abstract into a single column for raw text\n",
    "        data[\"raw_text\"] = data[\"title\"] + \" \" + data[\"abstract\"]\n",
    "\n",
    "        # Preprocess the raw text and store it in a new column\n",
    "        data[\"preprocessed_text\"] = data[\"raw_text\"].map(self.preprocess_text, meta=(\"raw_text\", \"str\"))\n",
    "\n",
    "        return data\n",
    "\n",
    "    def calculate_relevance_with_tfidf(self, query, documents):\n",
    "        \"\"\"\n",
    "        Uses TF-IDF to calculate relevance scores directly.\n",
    "        \"\"\"\n",
    "        # Convert Dask DataFrame to a list for TF-IDF vectorization\n",
    "        texts = documents[\"preprocessed_text\"].compute().tolist()\n",
    "        tfidf_matrix = self.vectorizer.fit_transform(texts)  # Keep sparse format\n",
    "\n",
    "        # Transform query into the same TF-IDF vector space\n",
    "        query_vector = self.vectorizer.transform([self.preprocess_text(query)])\n",
    "\n",
    "        # Calculate cosine similarity\n",
    "        relevance_scores = cosine_similarity(query_vector, tfidf_matrix).flatten()\n",
    "\n",
    "        # Map relevance scores back to document indices\n",
    "        doc_scores = {idx: relevance_scores[idx] for idx in range(len(texts))}\n",
    "        return doc_scores\n",
    "\n",
    "    def rank_snippets(self, query, top_documents, top_n_snippets=10):\n",
    "        \"\"\"\n",
    "        Extracts and ranks snippets globally from the top documents based on relevance.\n",
    "        \"\"\"\n",
    "        snippets = []\n",
    "        query_vector = self.vectorizer.transform([self.preprocess_text(query)])\n",
    "\n",
    "        for doc in top_documents:\n",
    "            doc_id, raw_text = doc[\"pmc_id\"], doc[\"raw_text\"]  # Use raw text for snippets\n",
    "            \n",
    "            # Split raw text into sentences\n",
    "            sentences = sent_tokenize(raw_text)\n",
    "            \n",
    "            # Preprocess each sentence for scoring but keep the raw version for display\n",
    "            preprocessed_sentences = [self.preprocess_text(sentence) for sentence in sentences]\n",
    "            sentence_vectors = self.vectorizer.transform(preprocessed_sentences)  # Transform preprocessed sentences\n",
    "            \n",
    "            # Compute cosine similarity\n",
    "            snippet_scores = cosine_similarity(query_vector, sentence_vectors).flatten()\n",
    "\n",
    "            # Collect all snippets from the document\n",
    "            snippets.extend([\n",
    "                {\"text\": sentences[i], \"source\": doc_id, \"score\": snippet_scores[i]}\n",
    "                for i in range(len(sentences))\n",
    "            ])\n",
    "\n",
    "        # Sort all snippets globally\n",
    "        top_snippets = sorted(snippets, key=lambda x: x[\"score\"], reverse=True)[:top_n_snippets]\n",
    "        return top_snippets\n",
    "\n",
    "    def get_relevant_documents_and_snippets(self, query, file_path, top_n_docs=10, top_n_snippets=10):\n",
    "        \"\"\"\n",
    "        Processes CSV file using Dask, scores documents based on relevance to the query, \n",
    "        and returns the top N most relevant documents and snippets.\n",
    "        \"\"\"\n",
    "        # Load documents from the CSV file\n",
    "        documents = self.load_csv_data(file_path)\n",
    "\n",
    "        if len(documents) == 0:\n",
    "            print(\"No valid documents found.\")\n",
    "            return [], []\n",
    "        \n",
    "        # Calculate relevance scores using optimized TF-IDF\n",
    "        relevance_scores = self.calculate_relevance_with_tfidf(query, documents)\n",
    "        \n",
    "        # Get the top N relevant documents by sorting relevance scores\n",
    "        sorted_docs = sorted(relevance_scores.items(), key=lambda x: x[1], reverse=True)[:top_n_docs]\n",
    "        top_documents = [\n",
    "            {\n",
    "                \"pmc_id\": documents.loc[idx, \"pmid\"].compute().iloc[0],  # Extract the first value\n",
    "                \"text\": documents.loc[idx, \"preprocessed_text\"].compute().iloc[0],  # Extract the first value\n",
    "                \"raw_text\": documents.loc[idx, \"raw_text\"].compute().iloc[0],  # Extract the first value\n",
    "                \"score\": score,\n",
    "            }\n",
    "            for idx, score in sorted_docs\n",
    "        ]\n",
    "        # Rank and retrieve top snippets\n",
    "        top_snippets = self.rank_snippets(query, top_documents, top_n_snippets)\n",
    "\n",
    "        return top_documents, top_snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CSV file: /Users/onurcanmemis/Desktop/Lectures/Information_Retrieval/Project/ir-bioasq/main_articles_head1000.csv\n",
      "\n",
      "Top Documents:\n",
      "PMC ID: 2143, Score: 0.2842\n",
      "PMC ID: 1126, Score: 0.1463\n",
      "PMC ID: 2142, Score: 0.1234\n",
      "PMC ID: 884, Score: 0.1220\n",
      "PMC ID: 1990, Score: 0.1067\n",
      "PMC ID: 938, Score: 0.1020\n",
      "PMC ID: 1629, Score: 0.0997\n",
      "PMC ID: 1792, Score: 0.0946\n",
      "PMC ID: 670, Score: 0.0905\n",
      "PMC ID: 2145, Score: 0.0900\n",
      "\n",
      "Top Snippets:\n",
      "Source: 2143\n",
      "Snippet: Interferon heated to 80degree C could not be reactivated at 40degree C or 55degree C. Interferon of higher apparent molecular weight was more heat-stable than that with lower apparent molecular weight.\n",
      "Score: 0.4360\n",
      "\n",
      "Source: 2143\n",
      "Snippet: The stabilizing effect of pH during heating on interferon in solution was greatest at low pH, such that pH 2 greater than pH 5 greater than pH 7 greater than or equal to pH 9; freeze-dried preparations of interferon were also more heat-stable at acid pH than at neutral pH.\n",
      "Score: 0.4071\n",
      "\n",
      "Source: 2143\n",
      "Snippet: It is postulated that the physicochemical alterations in the aqueous environment significantly affecting the stability of interferon operate by producing changes in the size and/or conformation of interferon molecules.\n",
      "Score: 0.3540\n",
      "\n",
      "Source: 2143\n",
      "Snippet: The degradation of biological activity of virus-induced murine interferon was determined in linear nonisothermal and multiple isothermal tests.\n",
      "Score: 0.3200\n",
      "\n",
      "Source: 2143\n",
      "Snippet: The rate of cooling of heated interferon significantly influenced its residual activity.\n",
      "Score: 0.3188\n",
      "\n",
      "Source: 2143\n",
      "Snippet: Rapid cooling and sudden freezing decreased the residual activities of interferons at pH 2 and 9 more than \"normal\" cooling, an effect not observed at pH 7.\n",
      "Score: 0.3111\n",
      "\n",
      "Source: 884\n",
      "Snippet: Comparative study of virological infections in asthmatic and nonasthmatic children.\n",
      "Score: 0.2944\n",
      "\n",
      "Source: 2142\n",
      "Snippet: The adsorption, penetration and uncoating steps of the viral replicative cycle were shown to be unaffected by pH variation.\n",
      "Score: 0.2399\n",
      "\n",
      "Source: 2143\n",
      "Snippet: Heat stability was a function of the H+-ion concentration rather than the ionic composition of the buffer; interferon solutions containing monovalent cations with different ionic radii had similar heat stability.\n",
      "Score: 0.2336\n",
      "\n",
      "Source: 1629\n",
      "Snippet: An association between viral hepatitis and two rheumatic disease syndromes has been observed.\n",
      "Score: 0.2216\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the file path and query\n",
    "file_path = \"/Users/onurcanmemis/Desktop/Lectures/Information_Retrieval/Project/ir-bioasq/main_articles_head1000.csv\"\n",
    "query = \"Effects of interferon on viral infections\"\n",
    "\n",
    "# Initialize the model\n",
    "model = QuerySpecificTFIDFModel()\n",
    "\n",
    "# Retrieve top documents and snippets\n",
    "top_documents,top_snippets = model.get_relevant_documents_and_snippets(\n",
    "    query=query,\n",
    "    file_path=file_path,\n",
    "    top_n_docs=10,\n",
    "    top_n_snippets=10\n",
    ")\n",
    "\n",
    "# Print results\n",
    "print(\"\\nTop Documents:\")\n",
    "for doc in top_documents:\n",
    "    print(f\"PMC ID: {doc['pmc_id']}, Score: {doc['score']:.4f}\")\n",
    "\n",
    "print(\"\\nTop Snippets:\")\n",
    "for snippet in top_snippets:\n",
    "    print(f\"Source: {snippet['source']}\")\n",
    "    print(f\"Snippet: {snippet['text']}\")\n",
    "    print(f\"Score: {snippet['score']:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilistic Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/onurcanmemis/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/onurcanmemis/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/onurcanmemis/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import dask.dataframe as dd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import nltk\n",
    "from rank_bm25 import BM25Okapi  # Import BM25 from rank_bm25 library\n",
    "\n",
    "# Download NLTK resources\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "\n",
    "\n",
    "class BM25ModelWithDask:\n",
    "    def __init__(self):\n",
    "        # Initialize stop words and lemmatizer\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"\n",
    "        Preprocesses text by removing stopwords, applying lowercase, and lemmatization.\n",
    "        If for_bm25 is True, returns a list of tokens for BM25. Otherwise, returns a single string.\n",
    "        \"\"\"\n",
    "        tokens = text.lower().split()  # Tokenize and convert to lowercase\n",
    "        tokens = [word for word in tokens if word.isalnum() and word not in self.stop_words]  # Remove stop words and punctuation\n",
    "        tokens = [self.lemmatizer.lemmatize(word) for word in tokens]  # Apply lemmatization only\n",
    "        return tokens \n",
    "\n",
    "    def load_documents(self, file_path):\n",
    "        \"\"\"\n",
    "        Loads CSV data using Dask and preprocesses the `title` and `abstract` fields.\n",
    "        Assumes the file has columns `pmid`, `title`, and `abstract`.\n",
    "        \"\"\"\n",
    "        print(f\"Loading documents from {file_path}\")\n",
    "        ddf = dd.read_csv(file_path)\n",
    "        ddf = ddf.dropna(subset=['pmid', 'title', 'abstract'])  # Drop rows with missing values\n",
    "\n",
    "        # Combine title and abstract, and preprocess\n",
    "        ddf['raw_text'] = ddf['title'] + \" \" + ddf['abstract']\n",
    "        ddf['preprocessed_text'] = ddf['raw_text'].map(self.preprocess_text, meta=('preprocessed_text', 'object'))\n",
    "        \n",
    "        return ddf\n",
    "\n",
    "    def calculate_bm25_scores(self, query_tokens, documents):\n",
    "        \"\"\"\n",
    "        Uses BM25 to calculate relevance scores between the query and all documents.\n",
    "        \"\"\"\n",
    "        bm25 = BM25Okapi(list(documents['preprocessed_text']))\n",
    "        relevance_scores = bm25.get_scores(query_tokens)\n",
    "        return relevance_scores\n",
    "\n",
    "    def get_top_snippets(self, query_tokens, top_documents, top_n=10):\n",
    "        \"\"\"\n",
    "        Extracts and ranks snippets globally from the top documents using BM25.\n",
    "        \"\"\"\n",
    "        snippets = []\n",
    "        \n",
    "        for _, doc in top_documents.iterrows():\n",
    "            pmid, abstract = doc['pmid'], doc['raw_text']\n",
    "            sentences = sent_tokenize(abstract)  # Split the abstract into sentences\n",
    "            \n",
    "            for sentence in sentences:\n",
    "                preprocessed_sentence = self.preprocess_text(sentence)\n",
    "                snippets.append({\"text\": sentence, \"tokens\": preprocessed_sentence, \"source\": pmid})\n",
    "        \n",
    "        # Combine all snippets into a single list for BM25\n",
    "        snippet_texts = [snippet[\"tokens\"] for snippet in snippets]\n",
    "        bm25 = BM25Okapi(snippet_texts)\n",
    "        snippet_scores = bm25.get_scores(query_tokens)\n",
    "        \n",
    "        # Add scores to snippets and sort them globally\n",
    "        for i, snippet in enumerate(snippets):\n",
    "            snippet[\"score\"] = snippet_scores[i]\n",
    "        \n",
    "        top_snippets = sorted(snippets, key=lambda x: x[\"score\"], reverse=True)[:top_n]\n",
    "        return top_snippets\n",
    "\n",
    "    def get_relevant_documents_and_snippets(self, query, file_path, top_n_docs=10, top_n_snippets=10):\n",
    "        \"\"\"\n",
    "        Retrieves top N most relevant documents and globally ranks snippets from them.\n",
    "        \"\"\"\n",
    "        # Load documents\n",
    "        documents = self.load_documents(file_path).compute()  # Convert Dask DataFrame to pandas DataFrame\n",
    "\n",
    "        if len(documents) == 0:\n",
    "            print(\"No valid documents found.\")\n",
    "            return [], []\n",
    "\n",
    "        # Preprocess the query\n",
    "        query_tokens = self.preprocess_text(query)\n",
    "\n",
    "        # Calculate BM25 relevance scores\n",
    "        relevance_scores = self.calculate_bm25_scores(query_tokens, documents)\n",
    "        documents['score'] = relevance_scores\n",
    "\n",
    "        # Get top N documents\n",
    "        top_documents = documents.nlargest(top_n_docs, 'score')\n",
    "\n",
    "        # Rank snippets globally from top documents\n",
    "        top_snippets = self.get_top_snippets(query_tokens, top_documents, top_n_snippets)\n",
    "\n",
    "        # Return both top documents and snippets\n",
    "        return top_documents, top_snippets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading documents from /Users/onurcanmemis/Desktop/Lectures/Information_Retrieval/Project/ir-bioasq/main_articles_head1000.csv\n",
      "\n",
      "Top Documents:\n",
      "PMC ID: 2143, Score: 13.0717\n",
      "PMC ID: 1126, Score: 9.4150\n",
      "PMC ID: 2142, Score: 8.3898\n",
      "PMC ID: 1990, Score: 6.2001\n",
      "PMC ID: 938, Score: 6.1988\n",
      "PMC ID: 884, Score: 5.9103\n",
      "PMC ID: 1468, Score: 5.7332\n",
      "PMC ID: 1628, Score: 5.7323\n",
      "PMC ID: 1792, Score: 5.7181\n",
      "PMC ID: 1629, Score: 5.5253\n",
      "\n",
      "Top Snippets:\n",
      "Source: 2143\n",
      "Snippet: Rapid cooling and sudden freezing decreased the residual activities of interferons at pH 2 and 9 more than \"normal\" cooling, an effect not observed at pH 7.\n",
      "Score: 4.3776\n",
      "\n",
      "Source: 1792\n",
      "Snippet: Effect of environmental pH on adenovirus-associated virus.\n",
      "Score: 4.1220\n",
      "\n",
      "Source: 2143\n",
      "Snippet: The stabilizing effect of pH during heating on interferon in solution was greatest at low pH, such that pH 2 greater than pH 5 greater than pH 7 greater than or equal to pH 9; freeze-dried preparations of interferon were also more heat-stable at acid pH than at neutral pH.\n",
      "Score: 3.9315\n",
      "\n",
      "Source: 884\n",
      "Snippet: Comparative study of virological infections in asthmatic and nonasthmatic children.\n",
      "Score: 3.2311\n",
      "\n",
      "Source: 1792\n",
      "Snippet: Under the acid conditions studied, the adenovirus helper and cell activities were only slightly suppressed, with the greatest effect due to aggregation of the virus particles.\n",
      "Score: 2.6973\n",
      "\n",
      "Source: 2143\n",
      "Snippet: It is postulated that the physicochemical alterations in the aqueous environment significantly affecting the stability of interferon operate by producing changes in the size and/or conformation of interferon molecules.\n",
      "Score: 2.6757\n",
      "\n",
      "Source: 2143\n",
      "Snippet: Interferon heated to 80degree C could not be reactivated at 40degree C or 55degree C. Interferon of higher apparent molecular weight was more heat-stable than that with lower apparent molecular weight.\n",
      "Score: 2.5460\n",
      "\n",
      "Source: 2143\n",
      "Snippet: The rate of cooling of heated interferon significantly influenced its residual activity.\n",
      "Score: 2.4958\n",
      "\n",
      "Source: 1468\n",
      "Snippet: The mixtures of viral fragments exhibited an increased deacetylase activity.\n",
      "Score: 2.4594\n",
      "\n",
      "Source: 1126\n",
      "Snippet: It was assumed, however, that some represented atypical clinical forms of EBV infection and that timing of specimen collection was a factor in explaining the paucity of Downey cells.\n",
      "Score: 2.3946\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_path = \"/Users/onurcanmemis/Desktop/Lectures/Information_Retrieval/Project/ir-bioasq/main_articles_head1000.csv\"\n",
    "\n",
    "# Define the query\n",
    "query = \"Effects of interferon on viral infections\"\n",
    "\n",
    "# Initialize the BM25 model\n",
    "bm25_model = BM25ModelWithDask()\n",
    "\n",
    "# Retrieve top documents and snippets\n",
    "top_documents, top_snippets = bm25_model.get_relevant_documents_and_snippets(\n",
    "    query=query,\n",
    "    file_path=file_path,\n",
    "    top_n_docs=10,\n",
    "    top_n_snippets=10\n",
    ")\n",
    "\n",
    "# Print the top documents\n",
    "print(\"\\nTop Documents:\")\n",
    "for _, doc in top_documents.iterrows():\n",
    "    print(f\"PMC ID: {doc['pmid']}, Score: {doc['score']:.4f}\")\n",
    "\n",
    "# Print the top snippets\n",
    "print(\"\\nTop Snippets:\")\n",
    "for snippet in top_snippets:\n",
    "    print(f\"Source: {snippet['source']}\")\n",
    "    print(f\"Snippet: {snippet['text']}\")\n",
    "    print(f\"Score: {snippet['score']:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic Retrieval Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic IR Model- Normal (No optimization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/onurcanmemis/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "import numpy as np\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import nltk\n",
    "\n",
    "# Download NLTK resources for sentence tokenization\n",
    "nltk.download('punkt')\n",
    "\n",
    "\n",
    "class SemanticRetrievalModelWithDask:\n",
    "    def __init__(self, model_name='all-MiniLM-L6-v2'):\n",
    "        \"\"\"\n",
    "        Initialize the semantic model using a pre-trained Sentence-BERT model.\n",
    "        \"\"\"\n",
    "        self.embedding_model = SentenceTransformer(model_name)\n",
    "\n",
    "    def preprocess_documents(self, file_path):\n",
    "        \"\"\"\n",
    "        Loads CSV data using Dask and preprocesses the `title` and `abstract` fields.\n",
    "        Assumes the file has columns `pmid`, `title`, and `abstract`.\n",
    "        \"\"\"\n",
    "        print(f\"Loading documents from {file_path}\")\n",
    "        ddf = dd.read_csv(file_path)\n",
    "        ddf = ddf.dropna(subset=['pmid', 'title', 'abstract'])  # Drop rows with missing values\n",
    "\n",
    "        # Combine title and abstract into a single column\n",
    "        ddf['text'] = ddf['title'] + \" \" + ddf['abstract']\n",
    "        return ddf\n",
    "\n",
    "    def encode_text_batch(self, texts):\n",
    "        \"\"\"\n",
    "        Encodes a batch of texts into embeddings using Sentence-BERT.\n",
    "        \"\"\"\n",
    "        return self.embedding_model.encode(texts, convert_to_tensor=True, batch_size=32)\n",
    "\n",
    "    def calculate_relevance(self, query_embedding, document_embeddings):\n",
    "        \"\"\"\n",
    "        Calculates cosine similarity between the query embedding and document embeddings.\n",
    "        \"\"\"\n",
    "        similarities = cosine_similarity(query_embedding, document_embeddings)\n",
    "        return similarities[0]\n",
    "\n",
    "    def rank_snippets(self, query_embedding, documents, top_n_snippets=10):\n",
    "        \"\"\"\n",
    "        Extracts and ranks snippets globally based on semantic similarity to the query.\n",
    "        \"\"\"\n",
    "        snippets = []\n",
    "        \n",
    "        for _, doc in documents.iterrows():\n",
    "            pmid, text = doc['pmid'], doc['text']\n",
    "            sentences = sent_tokenize(text)  # Split the document into sentences\n",
    "            \n",
    "            # Encode snippets and compute similarity\n",
    "            snippet_embeddings = self.encode_text_batch(sentences).cpu().numpy()\n",
    "            snippet_scores = cosine_similarity(query_embedding, snippet_embeddings)\n",
    "\n",
    "            # Store snippets with their scores\n",
    "            for i, sentence in enumerate(sentences):\n",
    "                snippets.append({\n",
    "                    \"text\": sentence,\n",
    "                    \"source\": pmid,\n",
    "                    \"score\": snippet_scores[0][i]\n",
    "                })\n",
    "\n",
    "        # Sort snippets globally by score\n",
    "        top_snippets = sorted(snippets, key=lambda x: x[\"score\"], reverse=True)[:top_n_snippets]\n",
    "        return top_snippets\n",
    "\n",
    "    def get_relevant_documents_and_snippets(self, query, file_path, top_n_docs=10, top_n_snippets=10):\n",
    "        \"\"\"\n",
    "        Retrieves top N most relevant documents and globally ranks snippets from them.\n",
    "        \"\"\"\n",
    "        # Load documents\n",
    "        ddf = self.preprocess_documents(file_path).compute()  # Convert Dask DataFrame to pandas DataFrame\n",
    "\n",
    "        if len(ddf) == 0:\n",
    "            print(\"No valid documents found.\")\n",
    "            return [], []\n",
    "\n",
    "        # Encode documents into embeddings\n",
    "        print(\"Encoding document embeddings...\")\n",
    "        document_embeddings = np.array(\n",
    "            [embedding.cpu().numpy() for embedding in self.encode_text_batch(ddf['text'].tolist())]\n",
    "        )\n",
    "\n",
    "        # Encode the query into an embedding\n",
    "        print(\"Encoding query embedding...\")\n",
    "        query_embedding = self.encode_text_batch([query]).cpu().numpy()\n",
    "\n",
    "        # Calculate relevance scores\n",
    "        print(\"Calculating relevance scores...\")\n",
    "        relevance_scores = self.calculate_relevance(query_embedding, document_embeddings)\n",
    "\n",
    "        # Add scores to the DataFrame\n",
    "        ddf['score'] = relevance_scores\n",
    "\n",
    "        # Get top N documents\n",
    "        top_documents_df = ddf.nlargest(top_n_docs, 'score')\n",
    "        top_documents = [\n",
    "            {\n",
    "                \"pmc_id\": row['pmid'],\n",
    "                \"text\": row['text'],\n",
    "                \"score\": row['score'],\n",
    "                \"url\": f\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC{row['pmid']}/\",\n",
    "            }\n",
    "            for _, row in top_documents_df.iterrows()\n",
    "        ]\n",
    "\n",
    "        # Rank snippets globally from top documents\n",
    "        print(\"Ranking snippets globally...\")\n",
    "        top_snippets = self.rank_snippets(query_embedding, top_documents_df, top_n_snippets)\n",
    "\n",
    "        # Return both top documents and snippets\n",
    "        return top_documents, top_snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading documents from /Users/onurcanmemis/Desktop/Lectures/Information_Retrieval/Project/ir-bioasq/main_articles_head1000.csv\n",
      "Encoding document embeddings...\n",
      "Encoding query embedding...\n",
      "Calculating relevance scores...\n",
      "Ranking snippets globally...\n",
      "\n",
      "Top Documents:\n",
      "PMC ID: 1990, Score: 0.3160, URL: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1990/\n",
      "PMC ID: 706, Score: 0.3121, URL: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC706/\n",
      "PMC ID: 1145, Score: 0.2733, URL: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1145/\n",
      "PMC ID: 978, Score: 0.2686, URL: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC978/\n",
      "PMC ID: 2021, Score: 0.2676, URL: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2021/\n",
      "PMC ID: 1960, Score: 0.2562, URL: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1960/\n",
      "PMC ID: 2143, Score: 0.2554, URL: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2143/\n",
      "PMC ID: 914, Score: 0.2519, URL: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC914/\n",
      "PMC ID: 2110, Score: 0.2515, URL: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2110/\n",
      "PMC ID: 789, Score: 0.2366, URL: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC789/\n",
      "\n",
      "Top Snippets:\n",
      "Source: 2143\n",
      "Snippet: It is postulated that the physicochemical alterations in the aqueous environment significantly affecting the stability of interferon operate by producing changes in the size and/or conformation of interferon molecules.\n",
      "Score: 0.4299\n",
      "\n",
      "Source: 2143\n",
      "Snippet: The rate of cooling of heated interferon significantly influenced its residual activity.\n",
      "Score: 0.4141\n",
      "\n",
      "Source: 2143\n",
      "Snippet: Interferon heated to 80degree C could not be reactivated at 40degree C or 55degree C. Interferon of higher apparent molecular weight was more heat-stable than that with lower apparent molecular weight.\n",
      "Score: 0.4079\n",
      "\n",
      "Source: 706\n",
      "Snippet: Thirteen out of 18 young out-patients with simple schizophrenia under neuroleptic treatment completed a double-blind cross-over trial with Madopar [L-Dopa + benserazid (a peripheral decarboxylase inhibitor)] and placebo.\n",
      "Score: 0.3750\n",
      "\n",
      "Source: 2143\n",
      "Snippet: The degradation of biological activity of virus-induced murine interferon was determined in linear nonisothermal and multiple isothermal tests.\n",
      "Score: 0.3645\n",
      "\n",
      "Source: 2143\n",
      "Snippet: The stabilizing effect of pH during heating on interferon in solution was greatest at low pH, such that pH 2 greater than pH 5 greater than pH 7 greater than or equal to pH 9; freeze-dried preparations of interferon were also more heat-stable at acid pH than at neutral pH.\n",
      "Score: 0.3639\n",
      "\n",
      "Source: 2143\n",
      "Snippet: A model is proposed that relates thermal inactivation to different possible molecular states of interferon.\n",
      "Score: 0.3625\n",
      "\n",
      "Source: 2143\n",
      "Snippet: The influence of physicochemical factors on the thermal inactivation of murine interferon.\n",
      "Score: 0.3516\n",
      "\n",
      "Source: 1990\n",
      "Snippet: The results showed that (1) poly I : C molecules 0.1-0.3 nm long were the most effective for interferon induction; (2) sonication of poly I : C reduced its molecular length and also the interferon-inducing activity, the degree of reduction varying in different fractions; and (3) the interferon-inducing activity of poly I: C of 0.1-0.3 nm obtained by sucrose density gradient centrifugation was higher than that poly I: C of corresponding length prepared by sonication.\n",
      "Score: 0.3451\n",
      "\n",
      "Source: 1145\n",
      "Snippet: While it is ineffective in most patients, especially those with widespread metastatic disease, it occasionally produces good results.\n",
      "Score: 0.3224\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "model = SemanticRetrievalModelWithDask()\n",
    "\n",
    "# Define the query and file path\n",
    "query = \"Multiple sclerosis treatments using interferon\"\n",
    "file_path = \"/Users/onurcanmemis/Desktop/Lectures/Information_Retrieval/Project/ir-bioasq/main_articles_head1000.csv\"\n",
    "\n",
    "# Get the top 10 documents and snippets\n",
    "top_documents, top_snippets = model.get_relevant_documents_and_snippets(\n",
    "    query=query,\n",
    "    file_path=file_path,\n",
    "    top_n_docs=10,\n",
    "    top_n_snippets=10\n",
    ")\n",
    "\n",
    "# Print top documents\n",
    "print(\"\\nTop Documents:\")\n",
    "for doc in top_documents:\n",
    "    print(f\"PMC ID: {doc['pmc_id']}, Score: {doc['score']:.4f}, URL: {doc['url']}\")\n",
    "\n",
    "print(\"\\nTop Snippets:\")\n",
    "for snippet in top_snippets:\n",
    "    print(f\"Source: {snippet['source']}\")\n",
    "    print(f\"Snippet: {snippet['text']}\")\n",
    "    print(f\"Score: {snippet['score']:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic IR Model- With Speed Ups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/onurcanmemis/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "import numpy as np\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import faiss  # For approximate nearest neighbors\n",
    "import torch\n",
    "import nltk\n",
    "\n",
    "# Download NLTK resources for sentence tokenization\n",
    "nltk.download('punkt')\n",
    "\n",
    "\n",
    "class SemanticRetrievalModelWithDaskOptimized:\n",
    "    def __init__(self, model_name='sentence-transformers/paraphrase-MiniLM-L3-v2', use_gpu=True):\n",
    "        \"\"\"\n",
    "        Initialize the semantic model using a pre-trained Sentence-BERT model.\n",
    "        \"\"\"\n",
    "        device = \"cuda\" if use_gpu and torch.cuda.is_available() else \"cpu\"\n",
    "        self.embedding_model = SentenceTransformer(model_name, device=device)\n",
    "\n",
    "    def preprocess_documents(self, file_path):\n",
    "        \"\"\"\n",
    "        Loads and preprocesses documents using Dask. Assumes the CSV file has columns `pmid`, `title`, and `abstract`.\n",
    "        \"\"\"\n",
    "        print(f\"Loading documents from {file_path}\")\n",
    "        ddf = dd.read_csv(file_path)\n",
    "        ddf = ddf.dropna(subset=['pmid', 'title', 'abstract'])  # Drop rows with missing values\n",
    "\n",
    "        # Combine title and abstract into a single text column\n",
    "        ddf['text'] = ddf['title'] + \" \" + ddf['abstract']\n",
    "        return ddf\n",
    "\n",
    "    def encode_batch_text(self, texts):\n",
    "        \"\"\"\n",
    "        Encodes a batch of texts into embeddings using the Sentence-BERT model.\n",
    "        \"\"\"\n",
    "        embeddings = self.embedding_model.encode(texts, convert_to_tensor=True, batch_size=32)\n",
    "        return embeddings.cpu()  # Ensure embeddings are moved to CPU\n",
    "\n",
    "    def build_faiss_index(self, embeddings):\n",
    "        \"\"\"\n",
    "        Builds a FAISS index for approximate nearest neighbor search.\n",
    "        \"\"\"\n",
    "        embeddings_np = np.array(embeddings)  # Convert embeddings to NumPy array\n",
    "        d = embeddings_np.shape[1]  # Dimension of embeddings\n",
    "        index = faiss.IndexFlatL2(d)\n",
    "        index.add(embeddings_np)  # Add embeddings to the index\n",
    "        return index\n",
    "\n",
    "    def search_faiss_index(self, index, query_embedding, top_k=10):\n",
    "        \"\"\"\n",
    "        Searches the FAISS index for the top-k most similar embeddings.\n",
    "        \"\"\"\n",
    "        query_embedding_np = query_embedding.cpu().numpy().reshape(1, -1)  # Move query embedding to CPU\n",
    "        distances, indices = index.search(query_embedding_np, top_k)\n",
    "        return distances[0], indices[0]\n",
    "\n",
    "    def filter_documents(self, query, documents, embeddings, top_n_docs=10):\n",
    "        \"\"\"\n",
    "        Filters documents using approximate semantic similarity.\n",
    "        \"\"\"\n",
    "        query_embedding = self.encode_batch_text([query])\n",
    "        index = self.build_faiss_index(embeddings)\n",
    "        distances, indices = self.search_faiss_index(index, query_embedding, top_n_docs)\n",
    "        \n",
    "        top_documents = [\n",
    "            {\n",
    "                \"pmc_id\": documents.iloc[i][\"pmid\"],\n",
    "                \"text\": documents.iloc[i][\"text\"],\n",
    "                \"score\": 1 / (1 + distances[idx]),  # Inverse scaling to normalize distance\n",
    "                \"url\": f\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC{documents.iloc[i]['pmid']}/\",\n",
    "            }\n",
    "            for idx, i in enumerate(indices)\n",
    "        ]\n",
    "        return top_documents, query_embedding\n",
    "\n",
    "    def rank_snippets(self, query_embedding, top_documents, top_n_snippets=10):\n",
    "        \"\"\"\n",
    "        Ranks snippets globally based on semantic similarity.\n",
    "        \"\"\"\n",
    "        snippets = []\n",
    "        for doc in top_documents:\n",
    "            sentences = sent_tokenize(doc[\"text\"])  # Split the document into sentences\n",
    "            snippet_embeddings = self.encode_batch_text(sentences)\n",
    "            snippet_scores = cosine_similarity(query_embedding.cpu().numpy(), snippet_embeddings.cpu().numpy())[0]\n",
    "            \n",
    "            for i, sentence in enumerate(sentences):\n",
    "                snippets.append({\n",
    "                    \"text\": sentence,\n",
    "                    \"source\": doc[\"pmc_id\"],\n",
    "                    \"score\": snippet_scores[i],\n",
    "                })\n",
    "\n",
    "        # Sort snippets globally by score\n",
    "        top_snippets = sorted(snippets, key=lambda x: x[\"score\"], reverse=True)[:top_n_snippets]\n",
    "        return top_snippets\n",
    "\n",
    "    def get_relevant_documents_and_snippets(self, query, file_path, top_n_docs=10, top_n_snippets=10):\n",
    "        \"\"\"\n",
    "        Retrieves top N most relevant documents and globally ranks snippets from them.\n",
    "        \"\"\"\n",
    "        # Load documents with Dask\n",
    "        ddf = self.preprocess_documents(file_path).compute()  # Convert Dask DataFrame to pandas DataFrame\n",
    "\n",
    "        if len(ddf) == 0:\n",
    "            print(\"No valid documents found.\")\n",
    "            return [], []\n",
    "\n",
    "        # Encode document embeddings in batches\n",
    "        print(\"Encoding document embeddings...\")\n",
    "        embeddings = np.array([embedding.cpu().numpy() for embedding in self.encode_batch_text(ddf['text'].tolist())])\n",
    "\n",
    "        # Filter top documents using semantic similarity\n",
    "        print(\"Filtering top documents...\")\n",
    "        top_documents, query_embedding = self.filter_documents(query, ddf, embeddings, top_n_docs=top_n_docs)\n",
    "\n",
    "        # Rank snippets globally\n",
    "        print(\"Ranking snippets globally...\")\n",
    "        top_snippets = self.rank_snippets(query_embedding, top_documents, top_n_snippets=top_n_snippets)\n",
    "\n",
    "        return top_documents, top_snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading documents from /Users/onurcanmemis/Desktop/Lectures/Information_Retrieval/Project/ir-bioasq/main_articles_head1000.csv\n",
      "Encoding document embeddings...\n",
      "Filtering top documents...\n",
      "Ranking snippets globally...\n",
      "\n",
      "Top 10 Documents:\n",
      "PMC ID: 1295, URL: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1295/, Score: 0.0398\n",
      "PMC ID: 2143, URL: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2143/, Score: 0.0397\n",
      "PMC ID: 1628, URL: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1628/, Score: 0.0389\n",
      "PMC ID: 1990, URL: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1990/, Score: 0.0379\n",
      "PMC ID: 1996, URL: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1996/, Score: 0.0379\n",
      "PMC ID: 725, URL: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC725/, Score: 0.0373\n",
      "PMC ID: 1801, URL: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1801/, Score: 0.0371\n",
      "PMC ID: 2396, URL: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2396/, Score: 0.0371\n",
      "PMC ID: 1296, URL: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1296/, Score: 0.0364\n",
      "PMC ID: 1145, URL: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1145/, Score: 0.0364\n",
      "\n",
      "Top 10 Snippets:\n",
      "Source: https://www.ncbi.nlm.nih.gov/pmc/articles/2143/\n",
      "Snippet: It is postulated that the physicochemical alterations in the aqueous environment significantly affecting the stability of interferon operate by producing changes in the size and/or conformation of interferon molecules.\n",
      "Score: 0.4390\n",
      "\n",
      "Source: https://www.ncbi.nlm.nih.gov/pmc/articles/2143/\n",
      "Snippet: Interferon heated to 80degree C could not be reactivated at 40degree C or 55degree C. Interferon of higher apparent molecular weight was more heat-stable than that with lower apparent molecular weight.\n",
      "Score: 0.4115\n",
      "\n",
      "Source: https://www.ncbi.nlm.nih.gov/pmc/articles/1295/\n",
      "Snippet: Prolonged survival of weakly incompatible skin allografts in mice (across the barrier presented by the MSA) can be induced by pretreating the recipients not only with a specific anti-MSA serum (obtained on day 5 after a single MSA-incompatible skin graft) but also be means of control serum obtained in a similar way from the recipients of fully compatible (syngeneic) skin grafts.\n",
      "Score: 0.4006\n",
      "\n",
      "Source: https://www.ncbi.nlm.nih.gov/pmc/articles/2143/\n",
      "Snippet: The rate of cooling of heated interferon significantly influenced its residual activity.\n",
      "Score: 0.3959\n",
      "\n",
      "Source: https://www.ncbi.nlm.nih.gov/pmc/articles/2143/\n",
      "Snippet: A model is proposed that relates thermal inactivation to different possible molecular states of interferon.\n",
      "Score: 0.3583\n",
      "\n",
      "Source: https://www.ncbi.nlm.nih.gov/pmc/articles/1628/\n",
      "Snippet: Vasculitis with hepatitis B antigenemia: long-term observation in nine patients.\n",
      "Score: 0.3560\n",
      "\n",
      "Source: https://www.ncbi.nlm.nih.gov/pmc/articles/1628/\n",
      "Snippet: The natural history of the disease is emphasized and the manifestations of patients with vasculitis who carry hepatitis B antigen are compared with those of vasculitis patients who are antigen negative.\n",
      "Score: 0.3497\n",
      "\n",
      "Source: https://www.ncbi.nlm.nih.gov/pmc/articles/2396/\n",
      "Snippet: A solid-phase system was set up, using antisera to cortisol-21-BSA conjucates coupled to CNBr-activated cellulose.\n",
      "Score: 0.3390\n",
      "\n",
      "Source: https://www.ncbi.nlm.nih.gov/pmc/articles/2143/\n",
      "Snippet: The stabilizing effect of pH during heating on interferon in solution was greatest at low pH, such that pH 2 greater than pH 5 greater than pH 7 greater than or equal to pH 9; freeze-dried preparations of interferon were also more heat-stable at acid pH than at neutral pH.\n",
      "Score: 0.3344\n",
      "\n",
      "Source: https://www.ncbi.nlm.nih.gov/pmc/articles/1628/\n",
      "Snippet: This report reviews the experience in nine biopsy-proven cases of hepatitis B-associated necrotizing vasculitis followed for up to six years.\n",
      "Score: 0.3193\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "model = SemanticRetrievalModelWithDaskOptimized()\n",
    "\n",
    "# Define the query and CSV file path\n",
    "query = \"Multiple sclerosis treatments using interferon\"\n",
    "file_path = \"/Users/onurcanmemis/Desktop/Lectures/Information_Retrieval/Project/ir-bioasq/main_articles_head1000.csv\"\n",
    "\n",
    "# Retrieve top documents and snippets\n",
    "top_documents, top_snippets = model.get_relevant_documents_and_snippets(\n",
    "    query=query,\n",
    "    file_path=file_path,\n",
    "    top_n_docs=10,\n",
    "    top_n_snippets=10\n",
    ")\n",
    "\n",
    "# Print the top 10 documents\n",
    "print(\"\\nTop 10 Documents:\")\n",
    "for doc in top_documents:\n",
    "    print(f\"PMC ID: {doc['pmc_id']}, URL: {doc['url']}, Score: {doc['score']:.4f}\")\n",
    "\n",
    "# Print the top 10 snippets\n",
    "print(\"\\nTop 10 Snippets:\")\n",
    "for snippet in top_snippets:\n",
    "    print(f\"Source: https://www.ncbi.nlm.nih.gov/pmc/articles/{snippet['source']}/\")\n",
    "    print(f\"Snippet: {snippet['text']}\")\n",
    "    print(f\"Score: {snippet['score']:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Commplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating SemanticRetrievalModelWithDaskOptimized...\n",
      "Loading documents from /Users/onurcanmemis/Desktop/Lectures/Information_Retrieval/Project/ir-bioasq/main_articles_head1000.csv\n",
      "Encoding document embeddings...\n",
      "Filtering top documents...\n",
      "Ranking snippets globally...\n",
      "Evaluating SemanticRetrievalModelWithDask...\n",
      "Loading documents from /Users/onurcanmemis/Desktop/Lectures/Information_Retrieval/Project/ir-bioasq/main_articles_head1000.csv\n",
      "Encoding document embeddings...\n",
      "Filtering top documents...\n",
      "Ranking snippets globally...\n",
      "Evaluating BM25ModelWithDask...\n",
      "Loading documents from /Users/onurcanmemis/Desktop/Lectures/Information_Retrieval/Project/ir-bioasq/main_articles_head1000.csv\n",
      "Evaluating QuerySpecificTFIDFModel...\n",
      "Loading CSV file: /Users/onurcanmemis/Desktop/Lectures/Information_Retrieval/Project/ir-bioasq/main_articles_head1000.csv\n",
      "\n",
      "Comparison Results:\n",
      "Model: SemanticRetrievalModelWithDaskOptimized, Time Taken: 4.01 seconds\n",
      "Model: SemanticRetrievalModelWithDask, Time Taken: 4.01 seconds\n",
      "Model: BM25ModelWithDask, Time Taken: 0.23 seconds\n",
      "Model: QuerySpecificTFIDFModel, Time Taken: 5.93 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Path to the CSV file\n",
    "csv_file_path = \"/Users/onurcanmemis/Desktop/Lectures/Information_Retrieval/Project/ir-bioasq/main_articles_head1000.csv\"\n",
    "\n",
    "# Query to use for comparison\n",
    "query = \"Multiple sclerosis treatments using interferon\"\n",
    "\n",
    "# Number of documents and snippets to retrieve\n",
    "top_n_docs = 10\n",
    "top_n_snippets = 10\n",
    "\n",
    "# List of models to compare\n",
    "models = [\n",
    "    {\n",
    "        \"name\": \"SemanticRetrievalModelWithDaskOptimized\",\n",
    "        \"class\": SemanticRetrievalModelWithDaskOptimized,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"SemanticRetrievalModelWithDask\",\n",
    "        \"class\": SemanticRetrievalModelWithDask,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"BM25ModelWithDask\",\n",
    "        \"class\": BM25ModelWithDask,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"QuerySpecificTFIDFModel\",\n",
    "        \"class\": QuerySpecificTFIDFModel,\n",
    "    },\n",
    "]\n",
    "\n",
    "# Function to measure execution time of a model\n",
    "def measure_execution_time(model_class, csv_file_path, query, top_n_docs, top_n_snippets):\n",
    "    model = model_class()  # Instantiate the model\n",
    "    start_time = time.time()\n",
    "    model.get_relevant_documents_and_snippets(\n",
    "        query, csv_file_path, top_n_docs=top_n_docs, top_n_snippets=top_n_snippets\n",
    "    )\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    return elapsed_time\n",
    "\n",
    "# Compare the models\n",
    "results = []\n",
    "for model_info in models:\n",
    "    model_name = model_info[\"name\"]\n",
    "    model_class = model_info[\"class\"]\n",
    "    print(f\"Evaluating {model_name}...\")\n",
    "    elapsed_time = measure_execution_time(\n",
    "        model_class, csv_file_path, query, top_n_docs, top_n_snippets\n",
    "    )\n",
    "    results.append({\"Model\": model_name, \"Time (seconds)\": elapsed_time})\n",
    "\n",
    "# Print results\n",
    "print(\"\\nComparison Results:\")\n",
    "for result in results:\n",
    "    print(f\"Model: {result['Model']}, Time Taken: {result['Time (seconds)']:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
